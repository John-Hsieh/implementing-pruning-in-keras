{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define relative utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#__conv_utils__\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from six.moves import range\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Input, Lambda, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "import numpy as np\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "import pickle\n",
    "\n",
    "def normalize_tuple(value, n, name):\n",
    "    \"\"\"Transforms a single int or iterable of ints into an int tuple.\n",
    "    # Arguments\n",
    "        value: The value to validate and convert. Could be an int, or any iterable\n",
    "          of ints.\n",
    "        n: The size of the tuple to be returned.\n",
    "        name: The name of the argument being validated, e.g. `strides` or\n",
    "          `kernel_size`. This is only used to format error messages.\n",
    "    # Returns\n",
    "        A tuple of n integers.\n",
    "    # Raises\n",
    "        ValueError: If something else than an int/long or iterable thereof was\n",
    "        passed.\n",
    "    \"\"\"\n",
    "    if isinstance(value, int):\n",
    "        return (value,) * n\n",
    "    else:\n",
    "        try:\n",
    "            value_tuple = tuple(value)\n",
    "        except TypeError:\n",
    "            raise ValueError('The `{}` argument must be a tuple of {} '\n",
    "                             'integers. Received: {}'.format(name, n, value))\n",
    "        if len(value_tuple) != n:\n",
    "            raise ValueError('The `{}` argument must be a tuple of {} '\n",
    "                             'integers. Received: {}'.format(name, n, value))\n",
    "        for single_value in value_tuple:\n",
    "            try:\n",
    "                int(single_value)\n",
    "            except ValueError:\n",
    "                raise ValueError('The `{}` argument must be a tuple of {} '\n",
    "                                 'integers. Received: {} including element {} '\n",
    "                                 'of type {}'.format(name, n, value, single_value,\n",
    "                                                     type(single_value)))\n",
    "    return value_tuple\n",
    "\n",
    "\n",
    "def normalize_padding(value):\n",
    "    padding = value.lower()\n",
    "    allowed = {'valid', 'same', 'causal'}\n",
    "    if K.backend() == 'theano':\n",
    "        allowed.add('full')\n",
    "    if padding not in allowed:\n",
    "        raise ValueError('The `padding` argument must be one of \"valid\", \"same\" '\n",
    "                         '(or \"causal\" for Conv1D). Received: {}'.format(padding))\n",
    "    return padding\n",
    "\n",
    "\n",
    "def convert_kernel(kernel):\n",
    "    \"\"\"Converts a Numpy kernel matrix from Theano format to TensorFlow format.\n",
    "    Also works reciprocally, since the transformation is its own inverse.\n",
    "    # Arguments\n",
    "        kernel: Numpy array (3D, 4D or 5D).\n",
    "    # Returns\n",
    "        The converted kernel.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid kernel shape or invalid data_format.\n",
    "    \"\"\"\n",
    "    kernel = np.asarray(kernel)\n",
    "    if not 3 <= kernel.ndim <= 5:\n",
    "        raise ValueError('Invalid kernel shape:', kernel.shape)\n",
    "    slices = [slice(None, None, -1) for _ in range(kernel.ndim)]\n",
    "    no_flip = (slice(None, None), slice(None, None))\n",
    "    slices[-2:] = no_flip\n",
    "    return np.copy(kernel[tuple(slices)])\n",
    "\n",
    "\n",
    "def conv_output_length(input_length, filter_size,\n",
    "                       padding, stride, dilation=1):\n",
    "    \"\"\"Determines output length of a convolution given input length.\n",
    "    # Arguments\n",
    "        input_length: integer.\n",
    "        filter_size: integer.\n",
    "        padding: one of `\"same\"`, `\"valid\"`, `\"full\"`.\n",
    "        stride: integer.\n",
    "        dilation: dilation rate, integer.\n",
    "    # Returns\n",
    "        The output length (integer).\n",
    "    \"\"\"\n",
    "    if input_length is None:\n",
    "        return None\n",
    "    assert padding in {'same', 'valid', 'full', 'causal'}\n",
    "    dilated_filter_size = (filter_size - 1) * dilation + 1\n",
    "    if padding == 'same':\n",
    "        output_length = input_length\n",
    "    elif padding == 'valid':\n",
    "        output_length = input_length - dilated_filter_size + 1\n",
    "    elif padding == 'causal':\n",
    "        output_length = input_length\n",
    "    elif padding == 'full':\n",
    "        output_length = input_length + dilated_filter_size - 1\n",
    "    return (output_length + stride - 1) // stride\n",
    "\n",
    "\n",
    "def conv_input_length(output_length, filter_size, padding, stride):\n",
    "    \"\"\"Determines input length of a convolution given output length.\n",
    "    # Arguments\n",
    "        output_length: integer.\n",
    "        filter_size: integer.\n",
    "        padding: one of `\"same\"`, `\"valid\"`, `\"full\"`.\n",
    "        stride: integer.\n",
    "    # Returns\n",
    "        The input length (integer).\n",
    "    \"\"\"\n",
    "    if output_length is None:\n",
    "        return None\n",
    "    assert padding in {'same', 'valid', 'full'}\n",
    "    if padding == 'same':\n",
    "        pad = filter_size // 2\n",
    "    elif padding == 'valid':\n",
    "        pad = 0\n",
    "    elif padding == 'full':\n",
    "        pad = filter_size - 1\n",
    "    return (output_length - 1) * stride - 2 * pad + filter_size\n",
    "\n",
    "\n",
    "def deconv_length(dim_size, stride_size, kernel_size, padding,\n",
    "                  output_padding, dilation=1):\n",
    "    \"\"\"Determines output length of a transposed convolution given input length.\n",
    "    # Arguments\n",
    "        dim_size: Integer, the input length.\n",
    "        stride_size: Integer, the stride along the dimension of `dim_size`.\n",
    "        kernel_size: Integer, the kernel size along the dimension of\n",
    "            `dim_size`.\n",
    "        padding: One of `\"same\"`, `\"valid\"`, `\"full\"`.\n",
    "        output_padding: Integer, amount of padding along the output dimension,\n",
    "            Can be set to `None` in which case the output length is inferred.\n",
    "        dilation: dilation rate, integer.\n",
    "    # Returns\n",
    "        The output length (integer).\n",
    "    \"\"\"\n",
    "    assert padding in {'same', 'valid', 'full'}\n",
    "    if dim_size is None:\n",
    "        return None\n",
    "\n",
    "    # Get the dilated kernel size\n",
    "    kernel_size = (kernel_size - 1) * dilation + 1\n",
    "\n",
    "    # Infer length if output padding is None, else compute the exact length\n",
    "    if output_padding is None:\n",
    "        if padding == 'valid':\n",
    "            dim_size = dim_size * stride_size + max(kernel_size - stride_size, 0)\n",
    "        elif padding == 'full':\n",
    "            dim_size = dim_size * stride_size - (stride_size + kernel_size - 2)\n",
    "        elif padding == 'same':\n",
    "            dim_size = dim_size * stride_size\n",
    "    else:\n",
    "        if padding == 'same':\n",
    "            pad = kernel_size // 2\n",
    "        elif padding == 'valid':\n",
    "            pad = 0\n",
    "        elif padding == 'full':\n",
    "            pad = kernel_size - 1\n",
    "\n",
    "        dim_size = ((dim_size - 1) * stride_size + kernel_size - 2 * pad +\n",
    "                    output_padding)\n",
    "\n",
    "    return dim_size\n",
    "def normalize_data_format(value):\n",
    "    \"\"\"Checks that the value correspond to a valid data format.\n",
    "    # Arguments\n",
    "        value: String or None. `'channels_first'` or `'channels_last'`.\n",
    "    # Returns\n",
    "        A string, either `'channels_first'` or `'channels_last'`\n",
    "    # Example\n",
    "    ```python\n",
    "        >>> from keras import backend as K\n",
    "        >>> K.normalize_data_format(None)\n",
    "        'channels_first'\n",
    "        >>> K.normalize_data_format('channels_last')\n",
    "        'channels_last'\n",
    "    ```\n",
    "    # Raises\n",
    "        ValueError: if `value` or the global `data_format` invalid.\n",
    "    \"\"\"\n",
    "    if value is None:\n",
    "        value = image_data_format()\n",
    "    data_format = value.lower()\n",
    "    if data_format not in {'channels_first', 'channels_last'}:\n",
    "        raise ValueError('The `data_format` argument must be one of '\n",
    "                         '\"channels_first\", \"channels_last\". Received: ' +\n",
    "                         str(value))\n",
    "    return data_format\n",
    "\n",
    "def _preprocess_conv2d_input(x, data_format, force_transpose=False):\n",
    "    \"\"\"Transpose and cast the input before the conv2d.\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n",
    "        force_transpose: boolean, whether force to transpose input from NCHW to NHWC\n",
    "                        if the `data_format` is `\"channels_first\"`.\n",
    "    # Returns\n",
    "        A tensor.\n",
    "    \"\"\"\n",
    "    # tensorflow doesn't support float64 for conv layer before 1.8.0\n",
    "    if (dtype(x) == 'float64' and\n",
    "            StrictVersion(tf.__version__.split('-')[0]) < StrictVersion('1.8.0')):\n",
    "        x = tf.cast(x, 'float32')\n",
    "    tf_data_format = 'NHWC'\n",
    "    if data_format == 'channels_first':\n",
    "        if not _has_nchw_support() or force_transpose:\n",
    "            x = tf.transpose(x, (0, 2, 3, 1))  # NCHW -> NHWC\n",
    "        else:\n",
    "            tf_data_format = 'NCHW'\n",
    "    return x, tf_data_format\n",
    "def conv2d(x, kernel, strides=(1, 1), padding='valid',\n",
    "           data_format=None, dilation_rate=(1, 1)):\n",
    "    \"\"\"2D convolution.\n",
    "    # Arguments\n",
    "        x: Tensor or variable.\n",
    "        kernel: kernel tensor.\n",
    "        strides: strides tuple.\n",
    "        padding: string, `\"same\"` or `\"valid\"`.\n",
    "        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n",
    "            Whether to use Theano or TensorFlow/CNTK data format\n",
    "            for inputs/kernels/outputs.\n",
    "        dilation_rate: tuple of 2 integers.\n",
    "    # Returns\n",
    "        A tensor, result of 2D convolution.\n",
    "    # Raises\n",
    "        ValueError: If `data_format` is neither\n",
    "            `\"channels_last\"` nor `\"channels_first\"`.\n",
    "    \"\"\"\n",
    "    data_format = normalize_data_format(data_format)\n",
    "\n",
    "    x, tf_data_format = _preprocess_conv2d_input(x, data_format)\n",
    "\n",
    "    padding = _preprocess_padding(padding)\n",
    "\n",
    "    # TF 2 arg conversion\n",
    "    kwargs = {}\n",
    "    if _is_tf_1():\n",
    "        kwargs['dilation_rate'] = dilation_rate\n",
    "    else:\n",
    "        kwargs['dilations'] = dilation_rate\n",
    "\n",
    "    x = tf.nn.convolution(\n",
    "        x, kernel,\n",
    "        strides=strides,\n",
    "        padding=padding,\n",
    "        data_format=tf_data_format,\n",
    "        **kwargs)\n",
    "    if data_format == 'channels_first' and tf_data_format == 'NHWC':\n",
    "        x = tf.transpose(x, (0, 3, 1, 2))  # NHWC -> NCHW\n",
    "    return x\n",
    "def image_data_format():\n",
    "    \"\"\"Returns the default image data format convention.\n",
    "    # Returns\n",
    "        A string, either `'channels_first'` or `'channels_last'`\n",
    "    # Example\n",
    "    ```python\n",
    "        >>> keras.backend.image_data_format()\n",
    "        'channels_first'\n",
    "    ```\n",
    "    \"\"\"\n",
    "    _IMAGE_DATA_FORMAT = 'channels_last'\n",
    "    return _IMAGE_DATA_FORMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputSpec(object):\n",
    "    \"\"\"Specifies the ndim, dtype and shape of every input to a layer.\n",
    "    Every layer should expose (if appropriate) an `input_spec` attribute:\n",
    "    a list of instances of InputSpec (one per input tensor).\n",
    "    A None entry in a shape is compatible with any dimension,\n",
    "    a None shape is compatible with any shape.\n",
    "    # Arguments\n",
    "        dtype: Expected datatype of the input.\n",
    "        shape: Shape tuple, expected shape of the input\n",
    "            (may include None for unchecked axes).\n",
    "        ndim: Integer, expected rank of the input.\n",
    "        max_ndim: Integer, maximum rank of the input.\n",
    "        min_ndim: Integer, minimum rank of the input.\n",
    "        axes: Dictionary mapping integer axes to\n",
    "            a specific dimension value.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dtype=None,\n",
    "                 shape=None,\n",
    "                 ndim=None,\n",
    "                 max_ndim=None,\n",
    "                 min_ndim=None,\n",
    "                 axes=None):\n",
    "        self.dtype = dtype\n",
    "        self.shape = shape\n",
    "        if shape is not None:\n",
    "            self.ndim = len(shape)\n",
    "        else:\n",
    "            self.ndim = ndim\n",
    "        self.max_ndim = max_ndim\n",
    "        self.min_ndim = min_ndim\n",
    "        self.axes = axes or {}\n",
    "\n",
    "    def __repr__(self):\n",
    "        spec = [('dtype=' + str(self.dtype)) if self.dtype else '',\n",
    "                ('shape=' + str(self.shape)) if self.shape else '',\n",
    "                ('ndim=' + str(self.ndim)) if self.ndim else '',\n",
    "                ('max_ndim=' + str(self.max_ndim)) if self.max_ndim else '',\n",
    "                ('min_ndim=' + str(self.min_ndim)) if self.min_ndim else '',\n",
    "                ('axes=' + str(self.axes)) if self.axes else '']\n",
    "        return 'InputSpec(%s)' % ', '.join(x for x in spec if x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "X_train=X_train.astype(np.float32)\n",
    "X_test=X_test.astype(np.float32)\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_train=2*X_train-1\n",
    "X_test=2*X_test-1\n",
    "\n",
    "data_train = X_train\n",
    "labels_train = Y_train\n",
    "data_test = X_test\n",
    "labels_test = Y_test\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "batch_size=100\n",
    "lr=0.001\n",
    "Training=True\n",
    "Compressing=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define modified layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pruned_Dense(Layer):\n",
    "    def __init__(self, n_neurons_out, **kwargs):\n",
    "        self.n_neurons_out = n_neurons_out\n",
    "        super(pruned_Dense,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        #define the variables of this layer in the build function:\n",
    "        n_neurons_in = input_shape[1]\n",
    "        # print(n_neurons_in)\n",
    "        # print(self.n_neurons_out)\n",
    "        stdv = 1/np.sqrt(n_neurons_in)\n",
    "        w = np.random.normal(size=[n_neurons_in, self.n_neurons_out], loc=0.0, scale=stdv).astype(np.float32)\n",
    "        self.w = K.variable(w)\n",
    "        b = np.zeros(self.n_neurons_out)\n",
    "        self.b = K.variable(b)\n",
    "        # w is the weight matrix, b is the bias. These are the trainable variables of this layer.\n",
    "        self.trainable_weights = [self.w, self.b]\n",
    "        # mask is a non-trainable weight that simulates pruning. the values of mask should be either 1 or 0, where 0 will prune a weight. We initialize mask to all ones:\n",
    "        mask = np.ones((n_neurons_in, self.n_neurons_out))\n",
    "        self.mask = K.variable(mask)\n",
    "\n",
    "    def call(self, x):\n",
    "        # define the input-output relationship in this layer in this function\n",
    "        pruned_w = self.w * self.mask\n",
    "        out = K.dot(x, pruned_w)\n",
    "        out = out + self.b\n",
    "        return out\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        #define the shape of this layer's output:\n",
    "        return (input_shape[0], self.n_neurons_out)\n",
    "\n",
    "    def get_mask(self):\n",
    "        #get the mask values\n",
    "        return K.get_value(self.mask)\n",
    "\n",
    "    def set_mask(self, mask):\n",
    "        #set new mask values to this layer\n",
    "        K.set_value(self.mask, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import activations\n",
    "import initializers\n",
    "import regularizers\n",
    "import constraints\n",
    "class _Conv2(Layer):\n",
    "\n",
    "    def __init__(self, rank,\n",
    "                 filters,\n",
    "                 kernel_size,\n",
    "                 droprate,\n",
    "                 strides=1,\n",
    "                 padding='valid',\n",
    "                 data_format=None,\n",
    "                 dilation_rate=1,\n",
    "                 activation=None,\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 \n",
    "                 **kwargs):\n",
    "        super(_Conv2, self).__init__(**kwargs)\n",
    "        self.rank = rank\n",
    "        self.filters = filters\n",
    "        self.kernel_size = normalize_tuple(kernel_size, rank,\n",
    "                                                      'kernel_size')\n",
    "        self.strides = normalize_tuple(strides, rank, 'strides')\n",
    "        self.padding = normalize_padding(padding)\n",
    "        self.data_format = normalize_data_format(data_format)\n",
    "        self.dilation_rate = normalize_tuple(dilation_rate, rank,\n",
    "                                                        'dilation_rate')\n",
    "        self.activation =activations.get(activation)\n",
    "        self.use_bias = use_bias\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    "        self.input_spec = InputSpec(ndim=self.rank + 2)\n",
    "        self.droprate = droprate\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        input_dim = input_shape[channel_axis]\n",
    "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
    "\n",
    "        self.kernel = self.add_weight(shape=kernel_shape,\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='kernel',\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(self.filters,),\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        name='bias',\n",
    "                                        regularizer=self.bias_regularizer,\n",
    "                                        constraint=self.bias_constraint)\n",
    "        else:\n",
    "            self.bias = None\n",
    "        # Set input spec.\n",
    "        self.input_spec = InputSpec(ndim=self.rank + 2,\n",
    "                                    axes={channel_axis: input_dim})\n",
    "        self.built = True\n",
    "\n",
    "\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.data_format == 'channels_last':\n",
    "            space = input_shape[1:-1]\n",
    "        elif self.data_format == 'channels_first':\n",
    "            space = input_shape[2:]\n",
    "        new_space = []\n",
    "        for i in range(len(space)):\n",
    "            new_dim = conv_output_length(\n",
    "                space[i],\n",
    "                self.kernel_size[i],\n",
    "                padding=self.padding,\n",
    "                stride=self.strides[i],\n",
    "                dilation=self.dilation_rate[i])\n",
    "            new_space.append(new_dim)\n",
    "        if self.data_format == 'channels_last':\n",
    "            return (input_shape[0],) + tuple(new_space) + (self.filters,)\n",
    "        elif self.data_format == 'channels_first':\n",
    "            return (input_shape[0], self.filters) + tuple(new_space)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'rank': self.rank,\n",
    "            'filters': self.filters,\n",
    "            'kernel_size': self.kernel_size,\n",
    "            'strides': self.strides,\n",
    "            'padding': self.padding,\n",
    "            'data_format': self.data_format,\n",
    "            'dilation_rate': self.dilation_rate,\n",
    "            'activation': activations.serialize(self.activation),\n",
    "            'use_bias': self.use_bias,\n",
    "            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n",
    "            'bias_initializer': initializers.serialize(self.bias_initializer),\n",
    "            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n",
    "            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
    "            'activity_regularizer':\n",
    "                regularizers.serialize(self.activity_regularizer),\n",
    "            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n",
    "            'bias_constraint': constraints.serialize(self.bias_constraint)\n",
    "        }\n",
    "        base_config = super(_Conv, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################Trash!!!!!!!##################\n",
    "\n",
    "class pruned_Conv2D(_Conv2): \n",
    "\n",
    "    def __init__(self, filters,\n",
    "                 kernel_size,\n",
    "                 droprate,\n",
    "                 strides=(1, 1),\n",
    "                 padding='valid',\n",
    "                 data_format=None,\n",
    "                 dilation_rate=(1, 1),\n",
    "                 activation=None,\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(pruned_Conv2D, self).__init__(\n",
    "            rank=2,\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding=padding,\n",
    "            data_format=data_format,\n",
    "            dilation_rate=dilation_rate,\n",
    "            activation=activation,\n",
    "            use_bias=use_bias,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            bias_initializer=bias_initializer,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=bias_regularizer,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            kernel_constraint=kernel_constraint,\n",
    "            bias_constraint=bias_constraint,\n",
    "            droprate=droprate,\n",
    "            **kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        input_dim = input_shape[channel_axis]\n",
    "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
    "\n",
    "        self.kernel = self.add_weight(shape=kernel_shape,\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='kernel',\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(self.filters,),\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        name='bias',\n",
    "                                        regularizer=self.bias_regularizer,\n",
    "                                        constraint=self.bias_constraint)\n",
    "        else:\n",
    "            self.bias = None\n",
    "        # Set input spec.\n",
    "        ########################adding new weights########################################################################\n",
    "        a = self.kernel.get_shape();\n",
    "        masker = np.random.rand(a.dims[0],a.dims[1],a.dims[2],a.dims[3]);\n",
    "        masker[masker[:,:,:,:]<self.droprate] = 0;\n",
    "        masker[masker[:,:,:,:]>=self.droprate] = 1;\n",
    "        #print(masker)\n",
    "        #print(K.get_value(self.kernel))\n",
    "        masker = K.variable(masker)\n",
    "        self.modifiedkernel = masker\n",
    "        \n",
    "        ########################adding new bias########################################################################\n",
    "       \n",
    "        a = self.bias.get_shape();\n",
    "        masker = np.random.rand(a.dims[0]);\n",
    "\n",
    "        masker[masker[:]<self.droprate] = 0;\n",
    "        masker[masker[:]>=self.droprate] = 1;\n",
    "        #print(masker)\n",
    "        masker = K.variable(masker)\n",
    "        self.modifiedbias = masker \n",
    "        \n",
    "        self.input_spec = InputSpec(ndim=self.rank + 2,\n",
    "                                    axes={channel_axis: input_dim})\n",
    "        self.built = True\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        #original call\n",
    "        if self.rank == 2:\n",
    "            outputs = K.conv2d(\n",
    "                inputs,\n",
    "                self.kernel,\n",
    "                strides=self.strides,\n",
    "                padding=self.padding,\n",
    "                data_format=self.data_format,\n",
    "                dilation_rate=self.dilation_rate)\n",
    "\n",
    "        if self.use_bias:\n",
    "            outputs = K.bias_add(\n",
    "                outputs,\n",
    "                self.bias,\n",
    "                data_format=self.data_format)\n",
    "\n",
    "        if self.activation is not None:\n",
    "            return self.activation(outputs)\n",
    "        return outputs\n",
    "        \n",
    "    \n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super(Conv2D, self).get_config()\n",
    "        config.pop('rank')\n",
    "        return config\n",
    "    \n",
    "\n",
    "    #def build(self, input_shape):\n",
    "    #    return\n",
    "    #def call(self, x):\n",
    "    #    return\n",
    "    #def get_output_shape_for(self,input_shape):\n",
    "    #    return\n",
    "    def get_mask(self):\n",
    "        return self.modifiedkernel\n",
    "    def set_mask(self):\n",
    "#self.set_weights(self.bias * masker)\n",
    "        #print(K.get_value(self.bias))\n",
    "        #if(valuebefore.all() == K.get_value(self.bias).all()):\n",
    "        #    print('no modification')\n",
    "        return self.modifiedbias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    batch_norm_alpha=0.9\n",
    "    batch_norm_eps=1e-4\n",
    "\n",
    "    model=Sequential()\n",
    "    print(dir(model.layers))\n",
    "    model.add(pruned_Conv2D(filters=64, kernel_size=3, strides=(1, 1), padding='valid',input_shape=[32,32,3],droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(pruned_Conv2D(filters=64, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "    model.add(pruned_Conv2D(filters=128, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(pruned_Conv2D(filters=128, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "    model.add(pruned_Conv2D(filters=256, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(pruned_Conv2D(filters=256, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    temp = pruned_Dense(512)\n",
    "    temp.build([None,512])\n",
    "    model.add(temp)\n",
    "\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    \n",
    "    temp = pruned_Dense(512)\n",
    "    temp.build([None,512])\n",
    "    model.add(temp)\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    \n",
    "    temp2 = pruned_Dense(10)\n",
    "    temp2.build([None,512])\n",
    "    model.add(temp2)\n",
    "    model.add(Activation('softmax'))\n",
    "    for i in model.layers:\n",
    "        print(i)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "initialized a dense\n",
      "initialized a dense\n",
      "initialized a dense\n",
      "initialized a dense\n",
      "initialized a dense\n",
      "initialized a dense\n",
      "<__main__.pruned_Conv2D object at 0x00000194504272B0>\n",
      "<keras.layers.core.Activation object at 0x0000019450427160>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000194504275F8>\n",
      "<__main__.pruned_Conv2D object at 0x000001944B63E5F8>\n",
      "<keras.layers.core.Activation object at 0x000001944EA7D908>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001944EA7D0B8>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000001944EAD8BA8>\n",
      "<__main__.pruned_Conv2D object at 0x000001944ECF02B0>\n",
      "<keras.layers.core.Activation object at 0x000001944ED5C278>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001944ED5C4A8>\n",
      "<__main__.pruned_Conv2D object at 0x000001944F846C88>\n",
      "<keras.layers.core.Activation object at 0x000001944F8DA940>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001944F8DA198>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000001944F8F8EB8>\n",
      "<__main__.pruned_Conv2D object at 0x000001944F9F5358>\n",
      "<keras.layers.core.Activation object at 0x000001944FA5E240>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001944FA5E470>\n",
      "<__main__.pruned_Conv2D object at 0x000001944FAB5C88>\n",
      "<keras.layers.core.Activation object at 0x000001944FB4B940>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001944FB4B198>\n",
      "<keras.layers.core.Flatten object at 0x000001944FB6AEB8>\n",
      "<__main__.pruned_Dense object at 0x000001944FC637F0>\n",
      "<keras.layers.core.Activation object at 0x000001944FC63358>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001944FD547B8>\n",
      "<__main__.pruned_Dense object at 0x000001944FD54048>\n",
      "<keras.layers.core.Activation object at 0x000001944FD869B0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000194500A0860>\n",
      "<__main__.pruned_Dense object at 0x00000194500A0F28>\n",
      "<keras.layers.core.Activation object at 0x000001944FD54AC8>\n",
      "10000/10000 [==============================] - 37s 4ms/step\n",
      "Accuracy: 89.94%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.backend import set_session\n",
    "# 程序开始时声明\n",
    "sess = tf.Session()\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "# 在model加载前添加set_session\n",
    "set_session(sess)\n",
    "\n",
    "#convert the layers to maskable_layers:\n",
    "model = get_model()\n",
    "    \n",
    "weights_path='pretrained_cifar10.h5'\n",
    "model.load_weights(weights_path)\n",
    "\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=0.001,decay=1e-6)\n",
    "#now complie the prunable model with sparse categorical crossentropy loss function as you did in part 1\n",
    "#make sure weights are loaded correctly by evaluating the prunable model here and printing the output\n",
    "model.compile(optimizer=opt, \n",
    "              loss=\"categorical_crossentropy\" ,metrics=['accuracy'])\n",
    "#history_dropout_hidden = model.fit(data_train, labels_train, validation_data=(data_test, labels_test), epochs=50, batch_size=1000, shuffle=True)\n",
    "\n",
    "scores_dropout_hidden = model.evaluate(data_test, labels_test)\n",
    "print(\"Accuracy: %.2f%%\" %(scores_dropout_hidden[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.pruned_Conv2D object at 0x00000194504272B0>\n",
      "<keras.layers.core.Activation object at 0x0000019450427160>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000194504275F8>\n",
      "<__main__.pruned_Conv2D object at 0x000001944B63E5F8>\n",
      "<keras.layers.core.Activation object at 0x000001944EA7D908>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001944EA7D0B8>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000001944EAD8BA8>\n",
      "<__main__.pruned_Conv2D object at 0x000001944ECF02B0>\n",
      "<keras.layers.core.Activation object at 0x000001944ED5C278>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001944ED5C4A8>\n",
      "<__main__.pruned_Conv2D object at 0x000001944F846C88>\n",
      "<keras.layers.core.Activation object at 0x000001944F8DA940>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001944F8DA198>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000001944F8F8EB8>\n",
      "<__main__.pruned_Conv2D object at 0x000001944F9F5358>\n",
      "<keras.layers.core.Activation object at 0x000001944FA5E240>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001944FA5E470>\n",
      "<__main__.pruned_Conv2D object at 0x000001944FAB5C88>\n",
      "<keras.layers.core.Activation object at 0x000001944FB4B940>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001944FB4B198>\n",
      "<keras.layers.core.Flatten object at 0x000001944FB6AEB8>\n",
      "<__main__.pruned_Dense object at 0x000001944FC637F0>\n",
      "<keras.layers.core.Activation object at 0x000001944FC63358>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001944FD547B8>\n",
      "<__main__.pruned_Dense object at 0x000001944FD54048>\n",
      "<keras.layers.core.Activation object at 0x000001944FD869B0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000194500A0860>\n",
      "<__main__.pruned_Dense object at 0x00000194500A0F28>\n",
      "<keras.layers.core.Activation object at 0x000001944FD54AC8>\n",
      "10000/10000 [==============================] - 41s 4ms/step\n",
      "Accuracy: 89.94%\n"
     ]
    }
   ],
   "source": [
    "global sess\n",
    "global graph\n",
    "with graph.as_default():\n",
    "    set_session(sess)\n",
    "for i in model.layers:\n",
    "    print(i)\n",
    "    if type(i) == pruned_Dense:\n",
    "        #print(dir(i))\n",
    "        #print(K.get_value(i.mask))\n",
    "        i.set_mask(i.get_mask())\n",
    "scores_dropout_hidden = model.evaluate(data_test, labels_test)\n",
    "print(\"Accuracy: %.2f%%\" %(scores_dropout_hidden[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer changer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class 'keras.layers.pooling.MaxPooling2D'>\n",
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class 'keras.layers.pooling.MaxPooling2D'>\n",
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class 'keras.layers.core.Flatten'>\n",
      "<class 'keras.layers.core.Dense'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class 'keras.layers.core.Dense'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class 'keras.layers.core.Dense'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "10000/10000 [==============================] - 36s 4ms/step\n",
      "Accuracy: 89.94%\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Input, Lambda, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "import numpy as np\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "import pickle\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "X_train=X_train.astype(np.float32)\n",
    "X_test=X_test.astype(np.float32)\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_train=2*X_train-1\n",
    "X_test=2*X_test-1\n",
    "\n",
    "data_train = X_train\n",
    "labels_train = Y_train\n",
    "data_test = X_test\n",
    "labels_test = Y_test\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "batch_size=100\n",
    "lr=0.001\n",
    "Training=True\n",
    "Compressing=False\n",
    "\n",
    "def get_model():\n",
    "\tbatch_norm_alpha=0.9\n",
    "\tbatch_norm_eps=1e-4\n",
    "\n",
    "\tmodel=Sequential()\n",
    "\n",
    "\tmodel.add(Conv2D(filters=64, kernel_size=3, strides=(1, 1), padding='valid',input_shape=[32,32,3]))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "\tmodel.add(Conv2D(filters=64, kernel_size=3, strides=(1, 1), padding='valid'))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "\tmodel.add(Conv2D(filters=128, kernel_size=3, strides=(1, 1), padding='valid'))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "\tmodel.add(Conv2D(filters=128, kernel_size=3, strides=(1, 1), padding='valid'))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "\tmodel.add(Conv2D(filters=256, kernel_size=3, strides=(1, 1), padding='valid'))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "\tmodel.add(Conv2D(filters=256, kernel_size=3, strides=(1, 1), padding='valid'))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "\t#model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "\tmodel.add(Flatten())\n",
    "\n",
    "\tmodel.add(Dense(512))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "\tmodel.add(Dense(512))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "\tmodel.add(Dense(10))\n",
    "\tmodel.add(Activation('softmax'))\n",
    "\n",
    "\treturn model\n",
    "\n",
    "\n",
    "test=get_model()\n",
    "weights_path='pretrained_cifar10.h5'\n",
    "test.load_weights(weights_path)\n",
    "for i in test.layers:\n",
    "    print(type(i))\n",
    "opt = keras.optimizers.Adam(lr=0.001,decay=1e-6)\n",
    "#now complie the prunable model with sparse categorical crossentropy loss function as you did in part 1\n",
    "#make sure weights are loaded correctly by evaluating the prunable model here and printing the output\n",
    "test.compile(optimizer=opt, \n",
    "              loss=\"categorical_crossentropy\" ,metrics=['accuracy'])\n",
    "#history_dropout_hidden = model.fit(data_train, labels_train, validation_data=(data_test, labels_test), epochs=50, batch_size=1000, shuffle=True)\n",
    "\n",
    "scores_dropout_hidden = test.evaluate(data_test, labels_test)\n",
    "print(\"Accuracy: %.2f%%\" %(scores_dropout_hidden[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized a dense\n",
      "initialized a dense\n",
      "initialized a dense\n",
      "initialized a dense\n",
      "initialized a dense\n",
      "initialized a dense\n",
      "<class '__main__.pruned_Conv2D'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class '__main__.pruned_Conv2D'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class 'keras.layers.pooling.MaxPooling2D'>\n",
      "<class '__main__.pruned_Conv2D'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class '__main__.pruned_Conv2D'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class 'keras.layers.pooling.MaxPooling2D'>\n",
      "<class '__main__.pruned_Conv2D'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class '__main__.pruned_Conv2D'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class 'keras.layers.core.Flatten'>\n",
      "<class '__main__.pruned_Dense'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class '__main__.pruned_Dense'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class '__main__.pruned_Dense'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "10000/10000 [==============================] - 35s 4ms/step\n",
      "Accuracy: 89.94%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.backend import set_session\n",
    "# 程序开始时声明\n",
    "sess = tf.Session()\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "# 在model加载前添加set_session\n",
    "set_session(sess)\n",
    "\n",
    "def convert_to_masked_model(model):\n",
    "    batch_norm_alpha=0.9\n",
    "    batch_norm_eps=1e-4\n",
    "\n",
    "    model2=Sequential()\n",
    "    for i in model.layers:\n",
    "        #if type(i) == keras.layers.convolutional.Conv2D:\n",
    "        #if type(i) == keras.layers.core.Dense:\n",
    "        if type(i) != keras.layers.convolutional.Conv2D and type(i) != keras.layers.core.Dense:\n",
    "            model2.add(i)\n",
    "        elif type(i) == keras.layers.convolutional.Conv2D:\n",
    "            temp2 = pruned_Conv2D(filters=i.filters, kernel_size=3, strides=i.strides, padding='valid',input_shape=(i.input_shape[1],i.input_shape[2],i.input_shape[3]))\n",
    "            temp2.build(i.input_shape)\n",
    "            #temp2.kernel = i.kernel\n",
    "            #temp2.bias = i.bias\n",
    "            temp2.set_weights(i.get_weights())\n",
    "            model2.add(temp2)\n",
    "        else:\n",
    "            temp2 = pruned_Dense(i.output_shape[1])\n",
    "            temp3 = [1,int(i.input_shape[1])]\n",
    "            temp2.build(temp3)\n",
    "            temp2.set_weights(i.get_weights())\n",
    "            model2.add(temp2)\n",
    "    \n",
    "    return model2\n",
    "\n",
    "\n",
    "    \n",
    "cask = convert_to_masked_model(test)\n",
    "for i in cask.layers:\n",
    "    print(type(i))\n",
    "opt = keras.optimizers.Adam(lr=0.001,decay=1e-6)\n",
    "#now complie the prunable model with sparse categorical crossentropy loss function as you did in part 1\n",
    "#make sure weights are loaded correctly by evaluating the prunable model here and printing the output\n",
    "cask.compile(optimizer=opt, \n",
    "              loss=\"categorical_crossentropy\" ,metrics=['accuracy'])\n",
    "#history_dropout_hidden = model.fit(data_train, labels_train, validation_data=(data_test, labels_test), epochs=50, batch_size=1000, shuffle=True)\n",
    "\n",
    "scores_dropout_hidden = cask.evaluate(data_test, labels_test)\n",
    "print(\"Accuracy: %.2f%%\" %(scores_dropout_hidden[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    batch_norm_alpha=0.9\n",
    "    batch_norm_eps=1e-4\n",
    "\n",
    "    model=Sequential()\n",
    "    print(dir(model.layers))\n",
    "    model.add(pruned_Conv2D(filters=64, kernel_size=3, strides=(1, 1), padding='valid',input_shape=[32,32,3],droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(pruned_Conv2D(filters=64, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "    model.add(pruned_Conv2D(filters=128, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(pruned_Conv2D(filters=128, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "    model.add(pruned_Conv2D(filters=256, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(pruned_Conv2D(filters=256, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    temp = pruned_Dense(512)\n",
    "    temp.build([None,512])\n",
    "    model.add(temp)\n",
    "\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    \n",
    "    temp = pruned_Dense(512)\n",
    "    temp.build([None,512])\n",
    "    model.add(temp)\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    \n",
    "    temp2 = pruned_Dense(10)\n",
    "    temp2.build([None,512])\n",
    "    model.add(temp2)\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "build started!!!! weights initialized\n",
      "call started!!!\n",
      "build started!!!! weights initialized\n",
      "call started!!!\n",
      "build started!!!! weights initialized\n",
      "call started!!!\n",
      "build started!!!! weights initialized\n",
      "call started!!!\n",
      "build started!!!! weights initialized\n",
      "call started!!!\n",
      "build started!!!! weights initialized\n",
      "call started!!!\n",
      "initialized a dense\n",
      "initialized a dense\n",
      "initialized a dense\n",
      "initialized a dense\n",
      "initialized a dense\n",
      "initialized a dense\n",
      "<class '__main__.pruned_Conv2D'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class '__main__.pruned_Conv2D'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class 'keras.layers.pooling.MaxPooling2D'>\n",
      "<class '__main__.pruned_Conv2D'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class '__main__.pruned_Conv2D'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class 'keras.layers.pooling.MaxPooling2D'>\n",
      "<class '__main__.pruned_Conv2D'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class '__main__.pruned_Conv2D'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class 'keras.layers.core.Flatten'>\n",
      "<class '__main__.pruned_Dense'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class '__main__.pruned_Dense'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class '__main__.pruned_Dense'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "10000/10000 [==============================] - 58s 6ms/step\n",
      "Accuracy: 89.94%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test=get_model()\n",
    "weights_path='pretrained_cifar10.h5'\n",
    "test.load_weights(weights_path)\n",
    "for i in test.layers:\n",
    "    print(type(i))\n",
    "opt = keras.optimizers.Adam(lr=0.001,decay=1e-6)\n",
    "#now complie the prunable model with sparse categorical crossentropy loss function as you did in part 1\n",
    "#make sure weights are loaded correctly by evaluating the prunable model here and printing the output\n",
    "test.compile(optimizer=opt, \n",
    "              loss=\"categorical_crossentropy\" ,metrics=['accuracy'])\n",
    "#history_dropout_hidden = model.fit(data_train, labels_train, validation_data=(data_test, labels_test), epochs=50, batch_size=1000, shuffle=True)\n",
    "\n",
    "scores_dropout_hidden = test.evaluate(data_test, labels_test)\n",
    "print(\"Accuracy: %.2f%%\" %(scores_dropout_hidden[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New dropmethod implemented, loop through effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pruned_Conv2D(_Conv2): \n",
    "\n",
    "    def __init__(self, filters,\n",
    "                 kernel_size,\n",
    "                 droprate,\n",
    "                 strides=(1, 1),\n",
    "                 padding='valid',\n",
    "                 data_format=None,\n",
    "                 dilation_rate=(1, 1),\n",
    "                 activation=None,\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(pruned_Conv2D, self).__init__(\n",
    "            rank=2,\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding=padding,\n",
    "            data_format=data_format,\n",
    "            dilation_rate=dilation_rate,\n",
    "            activation=activation,\n",
    "            use_bias=use_bias,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            bias_initializer=bias_initializer,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=bias_regularizer,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            kernel_constraint=kernel_constraint,\n",
    "            bias_constraint=bias_constraint,\n",
    "            droprate=droprate,\n",
    "            **kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        input_dim = input_shape[channel_axis]\n",
    "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
    "\n",
    "        self.kernel = self.add_weight(shape=kernel_shape,\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='kernel',\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(self.filters,),\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        name='bias',\n",
    "                                        regularizer=self.bias_regularizer,\n",
    "                                        constraint=self.bias_constraint)\n",
    "        else:\n",
    "            self.bias = None\n",
    "              \n",
    "        self.input_spec = InputSpec(ndim=self.rank + 2,\n",
    "                                    axes={channel_axis: input_dim})\n",
    "        self.built = True\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        #original call\n",
    "        if self.rank == 2:\n",
    "            outputs = K.conv2d(\n",
    "                inputs,\n",
    "                self.kernel,\n",
    "                strides=self.strides,\n",
    "                padding=self.padding,\n",
    "                data_format=self.data_format,\n",
    "                dilation_rate=self.dilation_rate)\n",
    "\n",
    "        if self.use_bias:\n",
    "            outputs = K.bias_add(\n",
    "                outputs,\n",
    "                self.bias,\n",
    "                data_format=self.data_format)\n",
    "\n",
    "        if self.activation is not None:\n",
    "            return self.activation(outputs)\n",
    "        return outputs\n",
    "    \n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super(Conv2D, self).get_config()\n",
    "        config.pop('rank')\n",
    "        return config\n",
    "    \n",
    "\n",
    "    #def build(self, input_shape):\n",
    "    #    return\n",
    "    #def call(self, x):\n",
    "    #    return\n",
    "    #def get_output_shape_for(self,input_shape):\n",
    "    #    return\n",
    "    def get_mask(self,kernelval):\n",
    "        ########new modification######\n",
    "        a = kernelval.shape\n",
    "        print(a)\n",
    "        masker = np.ones([a[0],a[1],a[2],a[3]]);\n",
    "        dropnum = int(self.droprate * int(a[0]) * int(a[1]) * int(a[2]) * int(a[3]))\n",
    "        #with tf.Session() as sess:\n",
    "        tempkernel = kernelval\n",
    "        i = 0;\n",
    "        while i<dropnum:\n",
    "            index = np.where(tempkernel == np.min(tempkernel))\n",
    "            tempkernel[index] = 999\n",
    "            masker[index] = 0\n",
    "            i = i+len(index)\n",
    "        modifiedkernel = kernelval * masker\n",
    "        return modifiedkernel\n",
    "    \n",
    "    \n",
    "    def set_mask(self,biasval):\n",
    "        #########new modification#######\n",
    "        a = biasval.shape\n",
    "        masker = np.ones(a[0]);\n",
    "        dropnum = int(self.droprate * int(a[0]))\n",
    "        \n",
    "        tempbias = biasval\n",
    "        for i in range(0,dropnum):\n",
    "            index = np.where(tempbias == np.min(tempbias))\n",
    "            tempbias[index] = 99999\n",
    "\n",
    "            masker[index] = 0\n",
    "\n",
    "        \n",
    "        modifiedbias = biasval * masker\n",
    "        return modifiedbias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(i):\n",
    "    batch_norm_alpha=0.9\n",
    "    batch_norm_eps=1e-4\n",
    "\n",
    "    model=Sequential()\n",
    "    print(dir(model.layers))\n",
    "    print(i)\n",
    "    model.add(pruned_Conv2D(filters=64, kernel_size=3, strides=(1, 1), padding='valid',input_shape=[32,32,3],droprate = i))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(pruned_Conv2D(filters=64, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "    model.add(pruned_Conv2D(filters=128, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(pruned_Conv2D(filters=128, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "    model.add(pruned_Conv2D(filters=256, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(pruned_Conv2D(filters=256, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    temp = pruned_Dense(512)\n",
    "    temp.build([None,512])\n",
    "    model.add(temp)\n",
    "\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    \n",
    "    temp = pruned_Dense(512)\n",
    "    temp.build([None,512])\n",
    "    model.add(temp)\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    \n",
    "    temp2 = pruned_Dense(10)\n",
    "    temp2.build([None,512])\n",
    "    model.add(temp2)\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.5\n",
      "(3, 3, 3, 64)\n",
      "10000/10000 [==============================] - 35s 3ms/step\n",
      "Accuracy: 16.65%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.55\n",
      "(3, 3, 3, 64)\n",
      "10000/10000 [==============================] - 37s 4ms/step\n",
      "Accuracy: 15.91%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.6\n",
      "(3, 3, 3, 64)\n",
      "10000/10000 [==============================] - 35s 4ms/step\n",
      "Accuracy: 14.58%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.65\n",
      "(3, 3, 3, 64)\n",
      "10000/10000 [==============================] - 35s 3ms/step\n",
      "Accuracy: 13.75%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.7\n",
      "(3, 3, 3, 64)\n",
      "10000/10000 [==============================] - 38s 4ms/step\n",
      "Accuracy: 12.97%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.75\n",
      "(3, 3, 3, 64)\n",
      "10000/10000 [==============================] - 39s 4ms/step\n",
      "Accuracy: 12.36%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.8\n",
      "(3, 3, 3, 64)\n",
      "10000/10000 [==============================] - 41s 4ms/step\n",
      "Accuracy: 11.97%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.85\n",
      "(3, 3, 3, 64)\n",
      "10000/10000 [==============================] - 41s 4ms/step\n",
      "Accuracy: 11.70%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.9\n",
      "(3, 3, 3, 64)\n",
      "10000/10000 [==============================] - 42s 4ms/step\n",
      "Accuracy: 11.45%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.95\n",
      "(3, 3, 3, 64)\n",
      "10000/10000 [==============================] - 42s 4ms/step\n",
      "Accuracy: 11.16%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.backend import set_session\n",
    "from keras.backend import manual_variable_initialization\n",
    "manual_variable_initialization(False)\n",
    "# 程序开始时声明\n",
    "sess = tf.Session()\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "# 在model加载前添加set_session\n",
    "set_session(sess)\n",
    "check = [50,55,60,65,70,75,80,85,90,95]#10,15,20,25,30,35,40,45,\n",
    "for i in check:\n",
    "    j = i/100\n",
    "    test=get_model(j)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    weights_path='pretrained_cifar10.h5'\n",
    "    test.load_weights(weights_path)\n",
    "    for p in test.layers:\n",
    "        if type(p) == pruned_Conv2D and p.droprate>0:\n",
    "            tempweight = p.get_mask(p.get_weights()[0])\n",
    "            #print(K.get_value(p.kernel))\n",
    "            tempweight2 = p.set_mask(p.get_weights()[1])\n",
    "            hoho = [tempweight,tempweight2]    \n",
    "            p.set_weights(hoho)\n",
    "    opt = keras.optimizers.Adam(lr=0.001,decay=1e-6)\n",
    "    #now complie the prunable model with sparse categorical crossentropy loss function as you did in part 1\n",
    "    #make sure weights are loaded correctly by evaluating the prunable model here and printing the output\n",
    "    test.compile(optimizer=opt, \n",
    "                  loss=\"categorical_crossentropy\" ,metrics=['accuracy'])\n",
    "    #history_dropout_hidden = model.fit(data_train, labels_train, validation_data=(data_test, labels_test), epochs=50, batch_size=1000, shuffle=True)\n",
    "\n",
    "    scores_dropout_hidden = test.evaluate(data_test, labels_test)\n",
    "    print(\"Accuracy: %.2f%%\" %(scores_dropout_hidden[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d618231080>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ans = [54.77,43.68,32.91,27.32,23.15,22.07,20.27,18.58,16.65,15.91,14.58,13.75,12.97,12.36,11.97,11.70,11.45,11.16]\n",
    "xaxis = [10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95]\n",
    "plt.plot(xaxis,ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(i):\n",
    "    batch_norm_alpha=0.9\n",
    "    batch_norm_eps=1e-4\n",
    "\n",
    "    model=Sequential()\n",
    "    print(dir(model.layers))\n",
    "    print(i)\n",
    "    model.add(pruned_Conv2D(filters=64, kernel_size=3, strides=(1, 1), padding='valid',input_shape=[32,32,3],droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(pruned_Conv2D(filters=64, kernel_size=3, strides=(1, 1), padding='valid',droprate = i))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "    model.add(pruned_Conv2D(filters=128, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(pruned_Conv2D(filters=128, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "    model.add(pruned_Conv2D(filters=256, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(pruned_Conv2D(filters=256, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    temp = pruned_Dense(512)\n",
    "    temp.build([None,512])\n",
    "    model.add(temp)\n",
    "\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    \n",
    "    temp = pruned_Dense(512)\n",
    "    temp.build([None,512])\n",
    "    model.add(temp)\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    \n",
    "    temp2 = pruned_Dense(10)\n",
    "    temp2.build([None,512])\n",
    "    model.add(temp2)\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.65\n",
      "(3, 3, 64, 64)\n",
      "10000/10000 [==============================] - 36s 4ms/step\n",
      "Accuracy: 62.42%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.7\n",
      "(3, 3, 64, 64)\n",
      "10000/10000 [==============================] - 41s 4ms/step\n",
      "Accuracy: 60.10%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.75\n",
      "(3, 3, 64, 64)\n",
      "10000/10000 [==============================] - 45s 4ms/step\n",
      "Accuracy: 57.32%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.8\n",
      "(3, 3, 64, 64)\n",
      "10000/10000 [==============================] - 53s 5ms/step\n",
      "Accuracy: 55.65%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.85\n",
      "(3, 3, 64, 64)\n",
      "10000/10000 [==============================] - 45s 5ms/step\n",
      "Accuracy: 53.00%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.9\n",
      "(3, 3, 64, 64)\n",
      "10000/10000 [==============================] - 45s 4ms/step\n",
      "Accuracy: 51.18%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.95\n",
      "(3, 3, 64, 64)\n",
      "10000/10000 [==============================] - 48s 5ms/step\n",
      "Accuracy: 49.29%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.backend import set_session\n",
    "from keras.backend import manual_variable_initialization\n",
    "manual_variable_initialization(False)\n",
    "# 程序开始时声明\n",
    "sess = tf.Session()\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "# 在model加载前添加set_session\n",
    "set_session(sess)\n",
    "check = [65,70,75,80,85,90,95]#10,15,20,25,30,35,40,45,50,55,60,\n",
    "for i in check:\n",
    "    j = i/100\n",
    "    test=get_model(j)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    weights_path='pretrained_cifar10.h5'\n",
    "    test.load_weights(weights_path)\n",
    "    for p in test.layers:\n",
    "        if type(p) == pruned_Conv2D and p.droprate>0:\n",
    "            tempweight = p.get_mask(p.get_weights()[0])\n",
    "            #print(K.get_value(p.kernel))\n",
    "            tempweight2 = p.set_mask(p.get_weights()[1])\n",
    "            hoho = [tempweight,tempweight2]    \n",
    "            p.set_weights(hoho)\n",
    "    opt = keras.optimizers.Adam(lr=0.001,decay=1e-6)\n",
    "    #now complie the prunable model with sparse categorical crossentropy loss function as you did in part 1\n",
    "    #make sure weights are loaded correctly by evaluating the prunable model here and printing the output\n",
    "    test.compile(optimizer=opt, \n",
    "                  loss=\"categorical_crossentropy\" ,metrics=['accuracy'])\n",
    "    #history_dropout_hidden = model.fit(data_train, labels_train, validation_data=(data_test, labels_test), epochs=50, batch_size=1000, shuffle=True)\n",
    "\n",
    "    scores_dropout_hidden = test.evaluate(data_test, labels_test)\n",
    "    print(\"Accuracy: %.2f%%\" %(scores_dropout_hidden[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f8bda3f550>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd4VHXe9/H3NwUCCT2FGmmhd0MvimBBFNRb7AqIYqGpe9+7ro+76+69u7qurqgoCiiCXVkQZAV1EektSIv03knooQRSfs8fGZ/l2UUywCRnZvJ5XRfXZE7Omfk41+HD8TfnnJ855xARkdAX4XUAEREJDBW6iEiYUKGLiIQJFbqISJhQoYuIhAkVuohImFChi4iECRW6iEiYUKGLiISJqOJ8s/j4eFe7du3ifEsRkZC3fPnyg865hMLWK9ZCr127NmlpacX5liIiIc/MdviznoZcRETChApdRCRMqNBFRMKECl1EJEz4VehmNsLM0s3sRzN7wresspl9a2abfI+VijaqiIhcSKGFbmbNgIeBdkBL4CYzSwGeBmY551KAWb7nIiLiEX+O0BsDi51zp5xzucAc4FagLzDBt84E4JaiiSgiIv7wp9DTgW5mVsXMygI3ArWAJOfcPgDfY2JRhVyw+SDvzt/G2dz8onoLEZGQV2ihO+fWAX8BvgVmAquAXH/fwMwGm1mamaVlZmZeUsiZ6fv5w/S1XPfKHGam70fzoIqI/Ce/vhR1zr3jnGvjnOsGHAY2AQfMrBqA7zHjZ7Yd45xLdc6lJiQUeuXqef2hb1PGD2hLVGQEj36wnDvfXsyqXUcv6bVERMKVv2e5JPoek4HbgI+BaUB/3yr9galFEdD3vnRvlMjMEV354y3N2JJ5gr5vLGDEJyvYfeRUUb2tiEhIMX+GL8xsHlAFyAGecs7NMrMqwGdAMrAT6OecO3yh10lNTXWBuJdLVnYOb83Zwrh523DAoC51eOzqepSPib7s1xYRCTZmttw5l1roesU5Hh2oQv/JnqOneenrDUxZsYcqsaV4omcKd7dLJipS10uJSPjwt9BDuvlqVCzDK3e24suhXaifGMdvpv7I9SPnMmvdAX1xKiIlTkgX+k+a16zAJ4M7MOb+K3EOBk1I495xS0jfc8zraCIixSYsCh0Kvji9rmlVvn6yG7/v05R1+45z86j5/OKzVew/lu11PBGRIhfSY+gXcux0Dm/O3sz4BduJiIDBXevyyFX1iC1drHN6iIhcthLxpag/dh0+xYtfb+DLVXuJjyvNo1fV5fqmValVuWyx5hARuVQq9H+zYucR/vzVOpZtPwJAg6Q4rmmURM/GibROrkRkhHmSS0SkMCr0n7Ht4ElmrTvAd+szWLrtMLn5jkplo+neMJEejZPo2iBe57OLSFBRofvh2Okc5m7M5Lv1GczekMHRUzlERRjt61amR6MkejRO5IoqsV7HFJESToV+kXLz8lmx6yj/XHeAWesy2JxxAoD6iXH0aFRw9N4muaIuWhKRYqdCv0w7Dp1k1roMZq0/wJKtBUMzFctGc3WDBHo0TuKqhgkamhGRYqFCD6Dj2TnM23iQWesPMHt9BkdO5RAdaXSuH0+vZlW5tklVKseW8jqmiIQpFXoRyct3rNh5hK9/3M+M9P3sPnKayAijfZ3K9GpWleubViWxfIzXMUUkjKjQi4Fzjh/3Hmdm+n5mpO9jS+ZJzODK5Erc0KwqNzSrSs1KOt9dRC6PCt0Dmw5kMSO94Mh93b7jADSvUYEbmlWlV7Oq1E2I8zihiIQiFbrHdhw66Tty389K3+xKDZPKFZR786o0TCqHmS5mEpHCBbTQzexJ4CHAAWuAgcBbwFXAT7c0HOCcW3mh1ylJhX6uvUdP/78x92XbD+Mc1ImP5YZmVbm3fbKGZUTkggJW6GZWA5gPNHHOnTazz4CvgKuB6c65Sf6GKqmFfq7MrDN8s3Y/M9P3s2jLIRLKlebvj3WiesUyXkcTkSAV6AkuooAyZhYFlAX2Xk64kiyhXGnubX8F7w9qz7ShXThxJpf731nCkZNnvY4mIiGu0EJ3zu0BXqJg3tB9wDHn3De+X//JzFab2StmVroIc4alJtXLM+6BVHYdOc3A95Zx6myu15FEJIQVWuhmVgnoC9QBqgOxZnYf8GugEdAWqAz86me2H2xmaWaWlpmZGbDg4aJ93SqMurs1q3cf5dEPfuBsbr7XkUQkRPkz5NIT2Oacy3TO5QCTgU7OuX2uwBlgPNDufBs758Y451Kdc6kJCQmBSx5Grmtaledva87cjZn8z6RV5OdrPlQRuXj+TN+zE+hgZmWB00APIM3Mqjnn9lnBuXe3AOlFmDPs3dk2mUMnz/LizA1Uji3Fb29qotMaReSiFFrozrklZjYJ+AHIBVYAY4AZZpYAGLASeLQog5YEj11Vj4NZZ3l3wTbi40ozpHt9ryOJSAjxa4JN59zvgN/92+JrAh+nZDMznu3dmMMnz/DXrzcQH1eKO9smex1LREKEZkwOMhERxl/7teTIqRx+PXkNFcuW4vqmVb2OJSIhQLM1BKHoyAhG39eGFjUrMuzjFSzZesjrSCISAlToQapsqSjGD2hLcuWyPDQxjbV7j3sdSUSCnAo9iFWKLcXEB9sRVzqK/uOXsvPQKa8jiUgQU6EHueoVyzDxwXbk5OXzwLtLyMw643UkEQlSKvQQkJJUjncHtOXA8TMMGL+UrOwcryOJSBBSoYeINsmVePO+NmzYn8XgicvJzsnzOpKIBBkVegjp3jCRl/q1ZNHWQzz56UrydIsAETmHCj3E3NK6Br+5qQkz0vfzm6npFOeMUyIS3HRhUQga1KUOB0+cYfT3W4iPK81T1zbwOpKIBAEVeoj65fUNOXTiDK/N2kR8XCke6Fjb60gi4jEVeogyM/58a3OOnMrhd9N+xID7OlyhOzSKlGAaQw9hUZERvH53a7qlJPCbqT/y8MTlHDqh89RFSioVeoiLiY5k/IC2/OamJszdlMn1I+cxe32G17FExAMq9DAQEWEM6lKHaUM7Ex9XioHvLeO3U9M5fVbnqouUJCr0MNKoanm+GNKZQV3qMHHRDm4eNZ/0Pce8jiUixcSvQjezJ83sRzNLN7OPzSzGzOqY2RIz22Rmn5pZqaIOK4WLiY7kNzc14YNB7cnKzuHWNxcw+vstughJpAQotNDNrAYwHEh1zjUDIoG7gL8ArzjnUoAjwKCiDCoXp0tKPDNHdKNn4yT+MnM994xdzJ6jp72OJSJFyN8hlyigjJlFAWWBfRRMQTfJ9/sJFEwULUGkUmwp3ry3DS/1a0n6nmPcMHIuU1fu8TqWiBSRQgvdObcHeAnYSUGRHwOWA0edc7m+1XYDNc63vZkNNrM0M0vLzMwMTGrxm5lx+5U1mTGiGw2SyjHik5WM+GQFx07rjo0i4cafIZdKQF+gDlAdiAV6nWfV8w7SOufGOOdSnXOpCQkJl5NVLkNylbJ8OrgDT13bgOmr99Fr5FwWa2o7kbDiz5BLT2Cbcy7TOZcDTAY6ARV9QzAANYG9RZRRAiQqMoLhPVL4+2OdKBUVwd1jF/PCjPWczc33OpqIBIA/hb4T6GBmZa3guvIewFpgNnC7b53+wNSiiSiB1qpWRf4xvCt3ta3FW3O2cOubC9ickeV1LBG5TP6MoS+h4MvPH4A1vm3GAL8CnjKzzUAV4J0izCkBFls6iudva8GY+69k37Fser82n4mLtut2vCIhzIrzL3BqaqpLS0srtvcT/2RkZfM/n69mzsZMrm2SxEv9WlKhTLTXsUTEx8yWO+dSC1tPV4oKieVieG9gwf1gZq/P4ObXdYWpSChSoQtQcHrjoC51+PSRjuTk5XPb6IV8tGSnhmBEQogKXf4/V15RienDutC+TmWembKGX3y2ilNncwvfUEQ8p0KX/1AlrjTvDWzHEz1TmLJyD7e8sYDNGSe8jiUihVChy3lFRhhP9GzAxAfbcfDEWfqOms+0VbrUQCSYqdDlgrqmJPCP4V1oVK08wz9ewe+mpnMmV/dZFwlGKnQpVLUKZfhkcAce6lKHCYt2cMfbi9l95JTXsUTk36jQxS/RkRE8e1MT3rqvDVszTnDT6/OZvUFT3YkEExW6XJQbmlXjy2FdqFahDAPHL+Olrzdo8gyRIKFCl4tWOz6WKY934s7UWoyavZn731lCZtYZr2OJlHgqdLkkMdGR/OX2Frx4ewuW7zhC79fmsUS34xXxlApdLssdqbX4YkhnYktHcc+4Jbw1Z4uuLhXxiApdLlvjauWZNrQz1zdN4oUZ63l44nKOndKMSCLFTYUuAVEuJpo37mnD725uwvcbMrjxtXks33HY61giJYoKXQLGzBjYuQ6THutERATc8fZi3pi9mXydBSNSLPyZU7Shma08589xM3vCzJ4zsz3nLL+xOAJL8PtpRqRezary16838MC7S8nIyvY6lkjYu6gJLswsEtgDtAcGAieccy/5u70muChZnHN8umwXz335I3Glo3j5jlZc1UAThYtcrKKa4KIHsMU5t+PSYklJYmbc1S6ZaUO7UDm2FP3fXcrzM9aRk6dJqUWKwsUW+l3Ax+c8H2pmq83sXTOrFMBcEkYaJJVj2tAu3NM+mbfnbKXfW4vYdVj3ghEJNL+HXMysFLAXaOqcO2BmScBBwAH/C1Rzzj14nu0GA4MBkpOTr9yxQwf3Jdk/Vu/j6cmrwcEL/9WC3i2qeR1JJOgVxZBLL+AH59wBAOfcAedcnnMuHxgLtDvfRs65Mc65VOdcakKCxk9Lut4tqvHV8K7US4xjyEc/8OvJazh9VrfjFQmEiyn0uzlnuMXMzj20uhVID1QoCW+1Kpfl80c78uhV9fh46U76vjGfjQeyvI4lEvL8KnQzKwtcC0w+Z/GLZrbGzFYD3YEniyCfhKnoyAie7tWIiQ+24/DJs/QZNZ+Pl2pSapHLcVGnLV4unbYo55ORlc1Tn65i/uaD9G5Rjedva075mGivY4kEjaI6bVEk4BLLxTDxwXb88oaGzEzfT+/X5rFy11GvY4mEHBW6BIWICOPxq+vz2SMdyM+H20cv5O05W3TbAJGLoEKXoHLlFZX5anhXejZO4vkZ63n8wx84cSbX61giIUGFLkGnQtloRt/Xhmd7N+abtfu57c0FbD940utYIkFPhS5Bycx4qGtdJj7YnoysM/QZNZ85GzO9jiUS1FToEtS6pMTz5dAuVK9YhoHjl2pGJJELUKFL0KtVuSyTH+9Er+bVeGHGeoZ/slJXl4qchwpdQkLZUlGMurs1v7qhEdNX7+W/Ri/UDb5E/o0KXUKGmfHY1fV4d0Bbdh05RZ9R81m4+aDXsUSChgpdQk73holMG9qFKnGluf/dpbw7f5vG1UVQoUuIqhMfyxdDOtOjUSJ/mL6WX3y+iuwcjatLyaZCl5AVVzqKt+67kid7NmDyD3u44+1F7D162utYIp5RoUtIi4gwRvRMYewDqWzNPEmfUfNZtv2w17FEPKFCl7BwbZMkvhjSiXIx0dw9ZjEfLN6hcXUpcVToEjbqJ5bjiyGd6ZoSz7NfpPPMlDWcydW4upQchRa6mTU0s5Xn/DluZk+YWWUz+9bMNvkeNUm0eK5CmWjG9W/LkO71+HjpLu4Zu4SM49lexxIpFoUWunNug3OulXOuFXAlcAqYAjwNzHLOpQCzfM9FPBcZYfzP9Y144542rN17nJte1/nqUjJc7JBLD2CLc24H0BeY4Fs+AbglkMFELlfvFtWY/Hgn4mKiuPedJfz5q3UagpGwdrGFfhf/mig6yTm3D8D3mBjIYCKB0Lhaef4xrCv3tEtmzNyt3PrGQjZpQmoJU34XupmVAvoAn1/MG5jZYDNLM7O0zEzd/lSKX5lSkfzp1uaMeyCVA8ezuen1+UxYuF1nwUjYuZgj9F7AD865A77nB8ysGoDvMeN8GznnxjjnUp1zqQkJCZeXVuQy9GySxIwnutKxXhV+N+1HBr63jIwsfWEq4eNiCv1u/jXcAjAN6O/7uT8wNVChRIpKYrkYxg9oyx/6NmXRlkP0GjmPf649UPiGIiHAr0I3s7LAtcDkcxa/AFxrZpt8v3sh8PFEAs/MeKBjbaYP60Ji+RgempjGM1PWcOqs5i6V0GbFOY6Ymprq0tLSiu39RApzJjePl7/ZyNh5W6kTH8urd7amec0KXscS+f+Y2XLnXGph6+lKUSnRSkdF8syNjflwUHtOncnj1jcX8Ob3m8nL1xemEnpU6CJAp/rxzHyiK9c3rcqLMzdwz9jF7NGdGyXEqNBFfCqWLcWoe1rzUr+WpO85xg0j5zJ15R6vY4n4TYUucg4z4/YrazJjRDdSEuMY8clKnvhkBcezc7yOJlIoFbrIeSRXKctnj3TkyZ4N+HL1PnqNnMfSbbrPugQ3FbrIz4iKjGBEzxQ+f7QjkRHGXWMWMW7eVl1hKkFLhS5SiDbJlfhqRFeua1KVP/5jHb/4TPOXSnBSoYv4Ia50FG/e24anrm3A5BUF85fuO6azYCS4qNBF/BQRYQzv8a/5S29+fQFpmr9UgogKXeQi/Wv+0ijuHruYD5fs8DqSCKBCF7kkP81f2qlePP9nSsH8pWdz872OJSWcCl3kElUoE827A9ry6FX1+GjJTu4dt5jMrDNex5ISTIUuchkiI4ynezXi9btbs2bPMfqMms/q3Ue9jiUllApdJABublmdvz/WiQgz+r21iCkrdnsdSUogFbpIgDStXoFpQzvTOrkiT366ij9OX0tunsbVpfio0EUCqEpcad4f1J4BnWozbv42BoxfxpGTZ72OJSWEvzMWVTSzSWa23szWmVlHM3vOzPaY2UrfnxuLOqxIKIiOjOC5Pk158fYWLN12mD5vzGf9/uNex5ISwN8j9FeBmc65RkBLYJ1v+SvOuVa+P18VSUKREHVHai0+eaQDZ3Lyue3NhcxYs8/rSBLmCi10MysPdAPeAXDOnXXO6Wt8ET+0Sa7E9GFdaFi1HI99+AMvf7OBfM2GJEXEnyP0ukAmMN7MVpjZODOL9f1uqJmtNrN3zazS+TY2s8FmlmZmaZmZmYHKLRIyEsvH8MngDtyZWovXv9vMoAnLyMjK9jqWhCF/Cj0KaAOMds61Bk4CTwOjgXpAK2Af8PL5NnbOjXHOpTrnUhMSEgKTWiTElI6K5IX/as7/9m3Kgi2HuO6VgtmQdCteCSR/Cn03sNs5t8T3fBLQxjl3wDmX55zLB8YC7YoqpEg4MDPu71ibr4Z3pU58LCM+Wckj7y/X0boETKGF7pzbD+wys4a+RT2AtWZW7ZzVbgXSiyCfSNipnxjHpEc78etejfh+Y6aO1iVg/D3LZRjwoZmtpmCI5c/Ai2a2xresO/BkEWUUCTuREcYjV9XT0boElBXnUUFqaqpLS0srtvcTCQV5+Y5x87by8rcbKVsqkt/3aUqfltUxM6+jSZAws+XOudTC1tOVoiIe09G6BIoKXSRIaGxdLpcKXSSI6GhdLocKXSQI6WhdLoUKXSRI6WhdLpYKXSTI6Whd/KVCFwkB5ztaf3jicvYdO+11NAkiKnSREPLT0fozNzZi/uZMrv3bXN5bsI083cFRUKGLhJzICGNwt3p888RVtE6uyHNfruW20QtZt0+TaJR0KnSREJVcpSwTH2zHyDtbsfvwKW5+fT4vzFjP6bN5XkcTj6jQRUKYmXFL6xr886mruLV1Dd6as4XrR85l3ibNPVASqdBFwkCl2FL8tV9LPnq4PZERxv3vLOXJT1dy6MQZr6NJMVKhi4SRTvXimTGiK8Ovqc/01Xvp8bc5TFq+W6c4lhAqdJEwExMdyVPXNeSr4V2pnxDHf3++invHLWHbwZNeR5MipkIXCVMpSeX47JGO/OnWZqzZc4zrR85l1HebOJub73U0KSJ+FbqZVTSzSWa23szWmVlHM6tsZt+a2Sbf43kniRYR70REGPe2v4JZT13FtY2TeOmbjdz0+jyW7zjsdTQpAv4eob8KzHTONQJaAusomCh6lnMuBZjley4iQSixfAxv3NuGcQ+kciI7l9vfWsSzX6zheHaO19EkgAqdscjMygOrgLrunJXNbANwtXNun29+0e+dcw1/7nVAMxaJBIOTZ3J5+ZuNvLdwG/FxpfnjLc24rmlVr2PJBQRyxqK6QCYw3sxWmNk4M4sFkpxz+wB8j4mXlVhEikVs6Sh+e3MTvhjSmfi40gx+fzm///JHja2HAX8KPQpoA4x2zrUGTnIRwytmNtjM0swsLTNTFzuIBIsWNSvyxZDODOhUm/ELttPv7UXsPnLK61hyGfwp9N3AbufcEt/zSRQU/AHfUAu+x4zzbeycG+OcS3XOpSYkJAQis4gESKmoCJ7r05Q3723D1owT9H5tPrPWHfA6llyiQgvdObcf2GVmP42P9wDWAtOA/r5l/YGpRZJQRIrcjc2r8eWwLtSoWIZBE9J4fsY6cvI0BBNqovxcbxjwoZmVArYCAyn4x+AzMxsE7AT6FU1EESkOteNjmfx4J/4wfS1vz9nKDzuO8PrdbahaIcbraOKnQs9yCSSd5SISGqau3MOvJ68hJjqSkXe2olsDDZd6KZBnuYhICdO3VQ2mDe1CQlxp+o9fyt++2aBJNEKACl1Ezqt+YhxfDOnM7W1q8tp3m7lv3BJNUB3kVOgi8rPKlIrkr/1a8uLtLVix6wg3vjqfhVsOeh1LfoYKXUQKdUdqLaYO6UL5MlHcN24Jr8/aRL6GYIKOCl1E/NKwajm+HNqFm1tW5+VvNzLgvWWaQCPIqNBFxG+xpaMYeWcr/nRrMxZvPUTv1+aTtl13bgwWKnQRuShmBbfknfxYJ0pHR3DnmMW8PWeLhmCCgApdRC5JsxoV+HJYF65vmsTzM9Zz+1sL+ebH/Sp2D6nQReSSlY+J5o172vD8bc05cPwMg99fTs+/zeGjJTvJzsnzOl6JoytFRSQgcvPy+Sp9P2PmbiF9z3Hi40rxQMfa3N/hCirFlvI6Xkjz90pRFbqIBJRzjkVbDzF27lZmb8gkJjqCO1JrMahLHa6oEut1vJDkb6H7e3MuERG/mBmd6sXTqV48Gw9kMXbuVj5eupP3F+/ghqZVGdytLq2TNQVxUdARuogUuYzj2by3cDsfLN7B8exc2tauxOBu9ejRKJGICPM6XtDTkIuIBJ0TZ3L5bNku3pm/jT1HT1M3PpaHutbltjY1iImO9Dpe0FKhi0jQys3LZ0b6fsbM3cqaPcf0BWohAlroZrYdyALygFznXKqZPQc8TMEE0gDPOOe+utDrqNBF5FzOORZvPczYeVv5bn0GMdERPHZVfYZ0r0dUpM6q/klRfCna3Tn377dZe8U599LFRRMRKWBmdKxXhY71qrDpQBavztrEK//cyLxNmYy8qxU1K5X1OmJI0T+BIhIUUpLKMeqeNrx6Vys27M+i16vzmL56r9exQoq/he6Ab8xsuZkNPmf5UDNbbWbvmpnOQxKRy9a3VQ2+GtGV+olxDP1oBb+ctIqTZ3K9jhUS/B1Dr+6c22tmicC3FEwavQE4SEHZ/y9QzTn34Hm2HQwMBkhOTr5yx44dAYwvIuEqJy+f12ZtYtTszdSuEstrd7Wmec0KXsfyREDnFHXO7fU9ZgBTgHbOuQPOuTznXD4wFmj3M9uOcc6lOudSExI00ayI+Cc6MoJfXNeQjx/uQHZOHreNXsCYubqr44UUWuhmFmtm5X76GbgOSDezauesdiuQXjQRRaQk61C3CjNGdKVHoyT+/NV6+o9fSsZxzW16Pv4coScB881sFbAU+IdzbibwopmtMbPVQHfgySLMKSIlWMWypRh9X8FdHZdtP8wNr87ju/UHvI4VdHRhkYiElM0ZWQz7eCXr9h1nQKfaPN2rUdhfZRrQMXQRkWBRP7EcUx7vxIOd6/Dewu3c8sYCNh3I8jpWUFChi0jIiYmO5Lc3N2H8gLZkZp3hptfn88HiHRTniEMwUqGLSMjq3iiRGU90pV2dyjz7RTqPvL+cIyfPeh3LMyp0EQlpieVimDCwHc/2bszsDRnc8OpcFm7597uUlAwqdBEJeRERxkNd6zLl8c7Elo7i3nFL+OWkVew8dMrraMVKhS4iYaNZjQpMH9aFgZ3q8MXKvXR/+Xv++/NVbD940utoxUKnLYpIWDpwPJu352zlwyU7yM139G1VnaHd61M3Ic7raBdNE1yIiAAZWdmMmbOVD5bs4GxuPn1aVmfoNSnUTwydYlehi4icIzPrDGPnbeX9RTvIzs3j5hbVGXZNfVKSynkdrVAqdBGR8zh04gxj521j4qLtnM7J48bm1Rh+TQoNqwZvsavQRUQu4PDJs4ybt5UJC7dz8mweNzavyrBrUmhcrbzX0f6DCl1ExA9HT53lnfnbeG/BdrLO5HJ90ySG90ihafXgufe6Cl1E5CIcO5XDOwu2MX7BNrKyc7m2SRIjeqTQrIb3xa5CFxG5BMdO5/Degu28M38rx33F/tS1DTwdilGhi4hchuPZBcU+dt5WsrJz6d2iGk/2TKF+YvF/eapCFxEJgGOnchg7byvjF2zjdE4et7SuwYgeKVxRJbbYMgS00M1sO5AF5AG5zrlUM6sMfArUBrYDdzjnjlzodVToIhKqDp04w9tzC86Kyct39EutydBrUqhRsUyRv3dRFHqqc+7gOcteBA47514ws6eBSs65X13odVToIhLqMo5n88bszXy8dBcAd7erxZDu9UksH1Nk71kchb4BuNo5t883YfT3zrmGF3odFbqIhIs9R08z6rtNfJa2m6gIo3+n2jzSrS5V4koH/L0CXejbgCOAA952zo0xs6POuYrnrHPEOVfpPNsOBgYDJCcnX7ljx46L+M8QEQluOw6d5NVZm/hixR5ioiN5sHMdHu5alwplowP2HoEu9OrOub1mlgh8CwwDpvlT6OfSEbqIhKvNGScY+c+NTF+9j3IxUTzctS4DO9emXMzlF3tAJ4l2zu31PWYAU4B2wAHfUAu+x4xLjysiEtrqJ8Yx6p42zBjRlQ51q/C3bzfS7cXZvD1nC6fP5hVLhkIL3cxizazcTz8D1wHpwDSgv2+1/sDUogopIhIqGlcrz9gHUpk6pDMtalbk+Rmyb/TxAAADnElEQVTr6fribBZuLvpp8aL8WCcJmGJmP63/kXNuppktAz4zs0HATqBf0cUUEQktLWtVZMKD7UjbfpjXvttMnYSiP29dFxaJiAS5gI6hi4hI8FOhi4iECRW6iEiYUKGLiIQJFbqISJhQoYuIhAkVuohImFChi4iEiWK9sMjMMoFwud1iPFD01/KGLn0+P0+fzYXp8/lPVzjnEgpbqVgLPZyYWZo/V26VVPp8fp4+mwvT53PpNOQiIhImVOgiImFChX7pxngdIMjp8/l5+mwuTJ/PJdIYuohImNARuohImFChF8LMapnZbDNbZ2Y/mtkI3/LKZvatmW3yPV5wPtVwZ2aRZrbCzKb7ntcxsyW+z+dTMyvldUavmFlFM5tkZut9+1FH7T8FzOxJ39+rdDP72MxitO9cOhV64XKBXzjnGgMdgCFm1gR4GpjlnEsBZvmel2QjgHXnPP8L8Irv8zkCDPIkVXB4FZjpnGsEtKTgcyrx+4+Z1QCGA6nOuWZAJHAX2ncumQq9EM65fc65H3w/Z1Hwl7EG0BeY4FttAnCLNwm9Z2Y1gd7AON9zA64BJvlWKbGfj5mVB7oB7wA45846546i/ecnUUAZM4sCygL70L5zyVToF8HMagOtgSVAknNuHxSUPpDoXTLPjQR+CeT7nlcBjjrncn3Pd1Pwj2BJVBfIBMb7hqTG+SZbL/H7j3NuD/ASBXMS7wOOAcvRvnPJVOh+MrM44O/AE865417nCRZmdhOQ4Zxbfu7i86xaUk+nigLaAKOdc62Bk5TA4ZXz8X1v0BeoA1QHYoFe51m1pO47F02F7gczi6agzD90zk32LT5gZtV8v68GZHiVz2OdgT5mth34hIL/XR4JVPT9bzRATWCvN/E8txvY7Zxb4ns+iYKC1/4DPYFtzrlM51wOMBnohPadS6ZCL4RvPPgdYJ1z7m/n/Goa0N/3c39ganFnCwbOuV8752o652pT8IXWd865e4HZwO2+1Ury57Mf2GVmDX2LegBr0f4DBUMtHcysrO/v2U+fjfadS6QLiwphZl2AecAa/jVG/AwF4+ifAckU7Jj9nHOHPQkZJMzsauC/nXM3mVldCo7YKwMrgPucc2e8zOcVM2tFwRfGpYCtwEAKDqZK/P5jZr8H7qTgbLIVwEMUjJlr37kEKnQRkTChIRcRkTChQhcRCRMqdBGRMKFCFxEJEyp0EZEwoUIXEQkTKnQRkTChQhcRCRP/FxUU0IzohVhCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "ans = [89.87,87.82,86.72,85.53,81.50,78.91,76.10,73.40,70.44,67.84,64.87,62.42,60.10,57.32,55.65,53.00,51.18,49.29]\n",
    "xaxis = [10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95]\n",
    "plt.plot(xaxis,ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3rd layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(i):\n",
    "    batch_norm_alpha=0.9\n",
    "    batch_norm_eps=1e-4\n",
    "\n",
    "    model=Sequential()\n",
    "    print(dir(model.layers))\n",
    "    print(i)\n",
    "    model.add(pruned_Conv2D(filters=64, kernel_size=3, strides=(1, 1), padding='valid',input_shape=[32,32,3],droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(pruned_Conv2D(filters=64, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "    model.add(pruned_Conv2D(filters=128, kernel_size=3, strides=(1, 1), padding='valid',droprate = i))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(pruned_Conv2D(filters=128, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "    model.add(pruned_Conv2D(filters=256, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(pruned_Conv2D(filters=256, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    temp = pruned_Dense(512)\n",
    "    temp.build([None,512])\n",
    "    model.add(temp)\n",
    "\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    \n",
    "    temp = pruned_Dense(512)\n",
    "    temp.build([None,512])\n",
    "    model.add(temp)\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    \n",
    "    temp2 = pruned_Dense(10)\n",
    "    temp2.build([None,512])\n",
    "    model.add(temp2)\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.8\n",
      "(3, 3, 64, 128)\n",
      "10000/10000 [==============================] - 41s 4ms/step\n",
      "Accuracy: 9.86%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.85\n",
      "(3, 3, 64, 128)\n",
      "10000/10000 [==============================] - 36s 4ms/step\n",
      "Accuracy: 9.76%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.9\n",
      "(3, 3, 64, 128)\n",
      "10000/10000 [==============================] - 35s 4ms/step\n",
      "Accuracy: 9.74%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.95\n",
      "(3, 3, 64, 128)\n",
      "10000/10000 [==============================] - 37s 4ms/step\n",
      "Accuracy: 9.78%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.backend import set_session\n",
    "from keras.backend import manual_variable_initialization\n",
    "manual_variable_initialization(False)\n",
    "# 程序开始时声明\n",
    "sess = tf.Session()\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "# 在model加载前添加set_session\n",
    "set_session(sess)\n",
    "check = [80,85,90,95]#10,15,20,25,30,35,40,45,50,55,60,65,70,75,\n",
    "for i in check:\n",
    "    j = i/100\n",
    "    test=get_model(j)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    weights_path='pretrained_cifar10.h5'\n",
    "    test.load_weights(weights_path)\n",
    "    for p in test.layers:\n",
    "        if type(p) == pruned_Conv2D and p.droprate>0:\n",
    "            tempweight = p.get_mask(p.get_weights()[0])\n",
    "            #print(K.get_value(p.kernel))\n",
    "            tempweight2 = p.set_mask(p.get_weights()[1])\n",
    "            hoho = [tempweight,tempweight2]    \n",
    "            p.set_weights(hoho)\n",
    "    opt = keras.optimizers.Adam(lr=0.001,decay=1e-6)\n",
    "    #now complie the prunable model with sparse categorical crossentropy loss function as you did in part 1\n",
    "    #make sure weights are loaded correctly by evaluating the prunable model here and printing the output\n",
    "    test.compile(optimizer=opt, \n",
    "                  loss=\"categorical_crossentropy\" ,metrics=['accuracy'])\n",
    "    #history_dropout_hidden = model.fit(data_train, labels_train, validation_data=(data_test, labels_test), epochs=50, batch_size=1000, shuffle=True)\n",
    "\n",
    "    scores_dropout_hidden = test.evaluate(data_test, labels_test)\n",
    "    print(\"Accuracy: %.2f%%\" %(scores_dropout_hidden[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2403a0909b0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ans = [81.42,65.44,42.21,24.46,16.71,13.28,11.61,10.67,10.28,10.08,9.95,9.81,9.81,9.86,9.76,9.74,9.78,9.71]\n",
    "xaxis = [10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95]\n",
    "plt.plot(xaxis,ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4th layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(i):\n",
    "    batch_norm_alpha=0.9\n",
    "    batch_norm_eps=1e-4\n",
    "\n",
    "    model=Sequential()\n",
    "    print(dir(model.layers))\n",
    "    print(i)\n",
    "    model.add(pruned_Conv2D(filters=64, kernel_size=3, strides=(1, 1), padding='valid',input_shape=[32,32,3],droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(pruned_Conv2D(filters=64, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "    model.add(pruned_Conv2D(filters=128, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(pruned_Conv2D(filters=128, kernel_size=3, strides=(1, 1), padding='valid',droprate = i))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "    model.add(pruned_Conv2D(filters=256, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(pruned_Conv2D(filters=256, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    temp = pruned_Dense(512)\n",
    "    temp.build([None,512])\n",
    "    model.add(temp)\n",
    "\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    \n",
    "    temp = pruned_Dense(512)\n",
    "    temp.build([None,512])\n",
    "    model.add(temp)\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    \n",
    "    temp2 = pruned_Dense(10)\n",
    "    temp2.build([None,512])\n",
    "    model.add(temp2)\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.9\n",
      "(3, 3, 128, 128)\n",
      "10000/10000 [==============================] - 36s 4ms/step\n",
      "Accuracy: 16.54%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.95\n",
      "(3, 3, 128, 128)\n",
      "10000/10000 [==============================] - 36s 4ms/step\n",
      "Accuracy: 15.24%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.backend import set_session\n",
    "from keras.backend import manual_variable_initialization\n",
    "manual_variable_initialization(False)\n",
    "# 程序开始时声明\n",
    "sess = tf.Session()\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "# 在model加载前添加set_session\n",
    "set_session(sess)\n",
    "check = [90,95]#10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,\n",
    "for i in check:\n",
    "    j = i/100\n",
    "    test=get_model(j)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    weights_path='pretrained_cifar10.h5'\n",
    "    test.load_weights(weights_path)\n",
    "    for p in test.layers:\n",
    "        if type(p) == pruned_Conv2D and p.droprate>0:\n",
    "            tempweight = p.get_mask(p.get_weights()[0])\n",
    "            #print(K.get_value(p.kernel))\n",
    "            tempweight2 = p.set_mask(p.get_weights()[1])\n",
    "            hoho = [tempweight,tempweight2]    \n",
    "            p.set_weights(hoho)\n",
    "    opt = keras.optimizers.Adam(lr=0.001,decay=1e-6)\n",
    "    #now complie the prunable model with sparse categorical crossentropy loss function as you did in part 1\n",
    "    #make sure weights are loaded correctly by evaluating the prunable model here and printing the output\n",
    "    test.compile(optimizer=opt, \n",
    "                  loss=\"categorical_crossentropy\" ,metrics=['accuracy'])\n",
    "    #history_dropout_hidden = model.fit(data_train, labels_train, validation_data=(data_test, labels_test), epochs=50, batch_size=1000, shuffle=True)\n",
    "\n",
    "    scores_dropout_hidden = test.evaluate(data_test, labels_test)\n",
    "    print(\"Accuracy: %.2f%%\" %(scores_dropout_hidden[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18fbea9b6a0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ans = [87.48,85.18,81.19,76.39,71.13,65.89,59.27,51.86,45.14,38.28,34.35,29.90,25.97,22.41,20.18,17.89,16.54,15.24]\n",
    "xaxis = [10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95]\n",
    "plt.plot(xaxis,ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5th layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(i):\n",
    "    batch_norm_alpha=0.9\n",
    "    batch_norm_eps=1e-4\n",
    "\n",
    "    model=Sequential()\n",
    "    print(dir(model.layers))\n",
    "    print(i)\n",
    "    model.add(pruned_Conv2D(filters=64, kernel_size=3, strides=(1, 1), padding='valid',input_shape=[32,32,3],droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(pruned_Conv2D(filters=64, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "    model.add(pruned_Conv2D(filters=128, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(pruned_Conv2D(filters=128, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "    model.add(pruned_Conv2D(filters=256, kernel_size=3, strides=(1, 1), padding='valid',droprate = i))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(pruned_Conv2D(filters=256, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    temp = pruned_Dense(512)\n",
    "    temp.build([None,512])\n",
    "    model.add(temp)\n",
    "\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    \n",
    "    temp = pruned_Dense(512)\n",
    "    temp.build([None,512])\n",
    "    model.add(temp)\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    \n",
    "    temp2 = pruned_Dense(10)\n",
    "    temp2.build([None,512])\n",
    "    model.add(temp2)\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.1\n",
      "(3, 3, 128, 256)\n",
      "10000/10000 [==============================] - 36s 4ms/step\n",
      "Accuracy: 88.93%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.15\n",
      "(3, 3, 128, 256)\n",
      "10000/10000 [==============================] - 37s 4ms/step\n",
      "Accuracy: 87.87%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.2\n",
      "(3, 3, 128, 256)\n",
      "10000/10000 [==============================] - 38s 4ms/step\n",
      "Accuracy: 86.32%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.25\n",
      "(3, 3, 128, 256)\n",
      "10000/10000 [==============================] - 35s 3ms/step\n",
      "Accuracy: 84.33%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.3\n",
      "(3, 3, 128, 256)\n",
      "10000/10000 [==============================] - 37s 4ms/step\n",
      "Accuracy: 81.63%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.35\n",
      "(3, 3, 128, 256)\n",
      "10000/10000 [==============================] - 38s 4ms/step\n",
      "Accuracy: 78.77%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.4\n",
      "(3, 3, 128, 256)\n",
      "10000/10000 [==============================] - 38s 4ms/step\n",
      "Accuracy: 75.99%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.45\n",
      "(3, 3, 128, 256)\n",
      "10000/10000 [==============================] - 40s 4ms/step\n",
      "Accuracy: 72.62%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.5\n",
      "(3, 3, 128, 256)\n",
      "10000/10000 [==============================] - 42s 4ms/step\n",
      "Accuracy: 68.94%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.55\n",
      "(3, 3, 128, 256)\n",
      "10000/10000 [==============================] - 42s 4ms/step\n",
      "Accuracy: 65.58%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.6\n",
      "(3, 3, 128, 256)\n",
      "10000/10000 [==============================] - 42s 4ms/step\n",
      "Accuracy: 61.15%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.65\n",
      "(3, 3, 128, 256)\n",
      "10000/10000 [==============================] - 43s 4ms/step\n",
      "Accuracy: 57.65%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 128, 256)\n",
      "10000/10000 [==============================] - 46s 5ms/step\n",
      "Accuracy: 54.63%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.75\n",
      "(3, 3, 128, 256)\n",
      "10000/10000 [==============================] - 43s 4ms/step\n",
      "Accuracy: 52.29%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.8\n",
      "(3, 3, 128, 256)\n",
      "10000/10000 [==============================] - 43s 4ms/step\n",
      "Accuracy: 50.38%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.85\n",
      "(3, 3, 128, 256)\n",
      "10000/10000 [==============================] - 43s 4ms/step\n",
      "Accuracy: 48.41%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.9\n",
      "(3, 3, 128, 256)\n",
      "10000/10000 [==============================] - 40s 4ms/step\n",
      "Accuracy: 47.08%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.95\n",
      "(3, 3, 128, 256)\n",
      "10000/10000 [==============================] - 42s 4ms/step\n",
      "Accuracy: 45.98%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.backend import set_session\n",
    "from keras.backend import manual_variable_initialization\n",
    "manual_variable_initialization(False)\n",
    "# 程序开始时声明\n",
    "sess = tf.Session()\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "# 在model加载前添加set_session\n",
    "set_session(sess)\n",
    "check = [10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95]#\n",
    "for i in check:\n",
    "    j = i/100\n",
    "    test=get_model(j)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    weights_path='pretrained_cifar10.h5'\n",
    "    test.load_weights(weights_path)\n",
    "    for p in test.layers:\n",
    "        if type(p) == pruned_Conv2D and p.droprate>0:\n",
    "            tempweight = p.get_mask(p.get_weights()[0])\n",
    "            #print(K.get_value(p.kernel))\n",
    "            tempweight2 = p.set_mask(p.get_weights()[1])\n",
    "            hoho = [tempweight,tempweight2]    \n",
    "            p.set_weights(hoho)\n",
    "    opt = keras.optimizers.Adam(lr=0.001,decay=1e-6)\n",
    "    #now complie the prunable model with sparse categorical crossentropy loss function as you did in part 1\n",
    "    #make sure weights are loaded correctly by evaluating the prunable model here and printing the output\n",
    "    test.compile(optimizer=opt, \n",
    "                  loss=\"categorical_crossentropy\" ,metrics=['accuracy'])\n",
    "    #history_dropout_hidden = model.fit(data_train, labels_train, validation_data=(data_test, labels_test), epochs=50, batch_size=1000, shuffle=True)\n",
    "\n",
    "    scores_dropout_hidden = test.evaluate(data_test, labels_test)\n",
    "    print(\"Accuracy: %.2f%%\" %(scores_dropout_hidden[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19090214198>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ans = [88.93,87.87,86.32,84.33,81.63,78.77,75.99,72.62,68.94,65.58,61.15,57.65,54.63,52.29,50.38,48.41,47.08,45.98]\n",
    "xaxis = [10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95]\n",
    "plt.plot(xaxis,ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Layer 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(i):\n",
    "    batch_norm_alpha=0.9\n",
    "    batch_norm_eps=1e-4\n",
    "\n",
    "    model=Sequential()\n",
    "    print(dir(model.layers))\n",
    "    print(i)\n",
    "    model.add(pruned_Conv2D(filters=64, kernel_size=3, strides=(1, 1), padding='valid',input_shape=[32,32,3],droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(pruned_Conv2D(filters=64, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "    model.add(pruned_Conv2D(filters=128, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(pruned_Conv2D(filters=128, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "    model.add(pruned_Conv2D(filters=256, kernel_size=3, strides=(1, 1), padding='valid',droprate = 0))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    model.add(pruned_Conv2D(filters=256, kernel_size=3, strides=(1, 1), padding='valid',droprate = i))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    temp = pruned_Dense(512)\n",
    "    temp.build([None,512])\n",
    "    model.add(temp)\n",
    "\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    \n",
    "    temp = pruned_Dense(512)\n",
    "    temp.build([None,512])\n",
    "    model.add(temp)\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "    \n",
    "    temp2 = pruned_Dense(10)\n",
    "    temp2.build([None,512])\n",
    "    model.add(temp2)\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.35\n",
      "(3, 3, 256, 256)\n",
      "10000/10000 [==============================] - 35s 3ms/step\n",
      "Accuracy: 88.14%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.4\n",
      "(3, 3, 256, 256)\n",
      "10000/10000 [==============================] - 35s 4ms/step\n",
      "Accuracy: 87.69%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.45\n",
      "(3, 3, 256, 256)\n",
      "10000/10000 [==============================] - 35s 4ms/step\n",
      "Accuracy: 87.07%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.5\n",
      "(3, 3, 256, 256)\n",
      "10000/10000 [==============================] - 36s 4ms/step\n",
      "Accuracy: 86.21%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.55\n",
      "(3, 3, 256, 256)\n",
      "10000/10000 [==============================] - 37s 4ms/step\n",
      "Accuracy: 84.91%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.6\n",
      "(3, 3, 256, 256)\n",
      "10000/10000 [==============================] - 38s 4ms/step\n",
      "Accuracy: 83.10%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.65\n",
      "(3, 3, 256, 256)\n",
      "10000/10000 [==============================] - 39s 4ms/step\n",
      "Accuracy: 80.69%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.7\n",
      "(3, 3, 256, 256)\n",
      "10000/10000 [==============================] - 38s 4ms/step\n",
      "Accuracy: 77.29%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.75\n",
      "(3, 3, 256, 256)\n",
      "10000/10000 [==============================] - 38s 4ms/step\n",
      "Accuracy: 73.37%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.8\n",
      "(3, 3, 256, 256)\n",
      "10000/10000 [==============================] - 39s 4ms/step\n",
      "Accuracy: 68.85%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.85\n",
      "(3, 3, 256, 256)\n",
      "10000/10000 [==============================] - 38s 4ms/step\n",
      "Accuracy: 64.40%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.9\n",
      "(3, 3, 256, 256)\n",
      "10000/10000 [==============================] - 39s 4ms/step\n",
      "Accuracy: 60.67%\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 256, 256)\n",
      "10000/10000 [==============================] - 39s 4ms/step\n",
      "Accuracy: 57.39%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.backend import set_session\n",
    "from keras.backend import manual_variable_initialization\n",
    "manual_variable_initialization(False)\n",
    "# 程序开始时声明\n",
    "sess = tf.Session()\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "# 在model加载前添加set_session\n",
    "set_session(sess)\n",
    "check = [35,40,45,50,55,60,65,70,75,80,85,90,95]#10,15,20,25,30,\n",
    "for i in check:\n",
    "    j = i/100\n",
    "    test=get_model(j)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    weights_path='pretrained_cifar10.h5'\n",
    "    test.load_weights(weights_path)\n",
    "    for p in test.layers:\n",
    "        if type(p) == pruned_Conv2D and p.droprate>0:\n",
    "            tempweight = p.get_mask(p.get_weights()[0])\n",
    "            #print(K.get_value(p.kernel))\n",
    "            tempweight2 = p.set_mask(p.get_weights()[1])\n",
    "            hoho = [tempweight,tempweight2]    \n",
    "            p.set_weights(hoho)\n",
    "    opt = keras.optimizers.Adam(lr=0.001,decay=1e-6)\n",
    "    #now complie the prunable model with sparse categorical crossentropy loss function as you did in part 1\n",
    "    #make sure weights are loaded correctly by evaluating the prunable model here and printing the output\n",
    "    test.compile(optimizer=opt, \n",
    "                  loss=\"categorical_crossentropy\" ,metrics=['accuracy'])\n",
    "    #history_dropout_hidden = model.fit(data_train, labels_train, validation_data=(data_test, labels_test), epochs=50, batch_size=1000, shuffle=True)\n",
    "\n",
    "    scores_dropout_hidden = test.evaluate(data_test, labels_test)\n",
    "    print(\"Accuracy: %.2f%%\" %(scores_dropout_hidden[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2bfc4209208>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8VPW9//HXJ/uekJCEIIQAAmHfAhWsC2DdSnGvctUitbXXSl1ab9VerXprrXqttlZrL1dU2rpUEcWq9aeitsV60bCGJexLAoGEJSsEsnx/f8yI0KKZhCRnMvN+Ph55TObMGebNPA7vOXzne84x5xwiItL1RXgdQERE2ocKXUQkRKjQRURChApdRCREqNBFREKECl1EJESo0EVEQoQKXUQkRKjQRURCRFRnvlj37t1dXl5eZ76kiEiXt2TJkj3OucyW1uvUQs/Ly6OwsLAzX1JEpMszs22BrKchFxGREKFCFxEJEQEVupndZGarzGy1md3sX5ZuZu+a2Qb/bbeOjSoiIl+mxUI3s2HAd4HxwEhgqpkNAG4HFjrnBgAL/fdFRMQjgeyhDwb+zzl3wDnXCPwVuAi4AJjrX2cucGHHRBQRkUAEUuirgNPNLMPMEoDzgd5AtnOuDMB/m9VxMUVEpCUtTlt0zq01sweBd4FaYAXQGOgLmNl1wHUAubm5bYwpIiItCWgeunNuDjAHwMzuB0qB3WaW45wrM7McoPwLnjsbmA1QUFDQpuvdvbdmN6t3VpMaH0VqQjQpcdGkxvt+Uvy3cdGRbfmjRURCRkCFbmZZzrlyM8sFLgYmAH2BGcAD/tsFHRXybxsq+P3HXz6vPiYqwl/0Uf9S9qnxn38IpMRHkRwXTXKc7zYpNorkuCh9IIhIl2eBXCTazP4OZAANwA+dcwvNLAN4CcgFtgOXOef2fdmfU1BQ4Np6pGhDUzM19Y1UHWyg6mAD1f7bqoMNVNd/vqz6YONxlze38NeMiYzwl/zRhX9s+SfHfr4sJT6KlDjfh0ZynO/3mChN6xeR9mdmS5xzBS2tF+iQy2nHWbYXmNKGbG0SHRlBemIM6YkxrX5uc7Oj7nCjv9wbqalvoKa+kZpD/tv6RqrrG6j1//7Z41v3HDjye+3hRlr67IuLjviXkk+JjyYlLuoLl/VMjSc7JRYza+M7IyLi06nncvFKRIT597SjoY2HPzU3O2oPH1v4NfW+D4jqev//DuobqT7YcOQDovLAYbbvO+B/rIGGpuN/IiTGRNI/K4mTM5Pon5VE/8xETs5KIjc9UXv9IhKwsCj09hARYb6967hoIL7Vz3fOUd/Q7PsQqG+g6qCv/Ev3H2BTRR0by2v5ePNe5i/bceQ5kRFGn/QEf8l/XvT9MpNIjY9ux7+diIQCFXonMTPiYyKJj4kkKyXuC9erPdTI5opaNlXUsrG8lk3ldWyqqOXDdeXH7OFnJsceKfj+mUmcnOX76ZESp+EbkTClQg8ySbFRjOiVxoheaccsb2hqpmTf53vzm/ylv2D5TmrqG495vq/ok4+UvG/4JoHICBW9SCgLaJZLezmRWS5yfM45KmoOsdG/R3/0T3nNoSPrxURF0K974pGx+pOzkhiQnUTf7onERmnKpkgwa9dZLhK8zIyslDiyUuKY2L/7MY9VHWzwD9vUHin8laWVvFVUdmTGToRBbnqCf08+mf6ZifTL9JV+aoLG6UW6EhV6CEuNj2Zsn26M7XPs1J6Dh5vYvKf2SNlv8O/R/3V9xTHj9BmJMfTPTKJfZuIxt726xRMVqdk3IsFGhR6G4mMiGdozlaE9U49Z3tjUTMn+g2wqr2XzHt8Xspv31PLOmt3sqys5sl50pJGXkXhU0Scd2bPX7BsR76jQ5YioyAj6dk+kb/dEIPuYx/bXHfaVfIVv1s3mijo2lNeycG05jUcdhts9yTf7ZthJqYzqncao3mn06havmTcinUBfisoJaWhqZvu+A2w+UvS+IZw1O6s51NgM+IZuRvZOY2SvNEblpjGyVyppCa0/4lckXOlLUekU0ZER/oOekvjaUXv1DU3NrNtVw/KSSpaXVLKipJIP1pUf+TI2LyOBUb3TfEXfO40hOSk6QZrICdIeunSa6voGVpVWsby0kuXbfUX/2dTK6EhjcE6Kr+R7+Uq+X/dEIjR3XiTgPXQVuniqrOogK0oqWV5SxfKS/RSVVlF3uAmAlLgoThuQyeT8LM4clElGUqzHaUW8oSEX6RJyUuPJSY3n3GE5ADQ1OzZV1LJ8eyWfbt3Hh+sreLOoDDMY1TuNyYOymJSfxdCeKfqiVeSfaA9dglpzs2P1zmoWFu/mg+JyVpRWAdAjJY5J+ZlMzs/m1JMzSIjRvomELg25SEgqr6nnw3UVfFBczt/WV1B3uImYqAgm9Mtgcn4Wk/Oz6J2e4HVMkXalQpeQd7ixmU+37mPh2nLeL97N1r0HABiQlcTkwVlMHpTF2D7ddFSrdHkqdAk7mytqeb+4nPeLy/lkyz4amx0pcVFMys/i6lP6MLZPN427S5ekQpewVlPfwKINe1hYXM47q3dRXd/IqN5pfOe0vpw7tIf22qVLUaGL+B043MgrS0qZs2gLW/ce4KS0eGaemsc3x/X2X4FKJLip0EX+SVOz4/3icp76+2YWb9lHUmwUl4/rzTUT8/RFqgQ1FbrIlygqrWLOos28sbKMZuc4b1gO157WlzG5bbyKuEgHatdCN7NbgO8ADigCZgK/A84AqvyrXeOcW/5lf44KXYJNWdVB5v5jG88v3kZ1fSNjctP4zmn9OHtItsbZJWi0W6Gb2UnAImCIc+6gmb0EvAWcCbzhnJsXaCgVugSrukONzPOPs2/fd4Be3eKZeWpfLh/Xm6RYHbQk3gq00APdBYkC4s0sCkgAdp5IOJFgkxgbxYyJeXxw65n87qqx5KTG8bM31jDh/oXc/9ZadlQe9DqiSIsCHXK5Cfg5cBB4xzl3pZk9C0wADgELgdudc4e++E/RHrp0LStKKpmzaAtvFpUBMHVEDredm0/PtHiPk0m4ac8hl27AK8DlQCXwMjAPX4nvAmKA2cAm59x/Hef51wHXAeTm5o7dtm1b6/4mIh7bUXmQuf/Yyu8/3kqkGbd8bSDXTMzTGLt0mvYccjkL2OKcq3DONQDzgYnOuTLncwh4Bhh/vCc752Y75wqccwWZmZmt+TuIBIWT0uL5yfmDefeWMxjfN5373lzLtMc/YnlJpdfRRI4RSKFvB04xswTzHTc9BVhrZjkA/mUXAqs6LqaI93qnJ/D0NeN48sox7K07xEW//Yi7XltFdX2D19FEgADOh+6cW2xm84ClQCOwDN8Qy1/MLBMwYDnw7x0ZVCQYmBnnDc/hqwO688t31vP7j7fy9upd/HTqEKaOyNG5YsRTOrBI5AQUlVbxk1eLKNpRxekDM/nZBUPpk5HodSwJMe09bVFEjmN4r1Reu+FU7vnGEJZu28/Zj/6Nx9/fwOHGZq+jSRhSoYucoMgI45pT+/LeD89gyuAsHn5nPec/9ncWb97rdTQJMyp0kXbSIzWO3145lmeuGUd9QxOXz/4//uPlFeyrO+x1NAkTKnSRdjYpP4t3bzmD68/sz6vLdjDllx/yUmEJnfl9lYQnFbpIB4iPieS2c/N588bT6J+ZxI/nreTy2f/Hht01XkeTEKZCF+lAg3ok89L3JvDAxcNZt6uG8x/7O4+8u56mZu2tS/tToYt0sIgI44rxubz/ozOYOqInjy3cwLVzP9UBSdLuVOginSQjKZZHLx/Fzy8axqINe7joiY/YsqfO61gSQlToIp3syq/04Q/XfoV9dYe58ImP+GjjHq8jSYhQoYt4YEL/DBbc8FWyU2L51tOf8PuPt2oWjJwwFbqIR3IzEnjl+olMGpTJTxes5j9fW0VDk44wlbZToYt4KDkumv+5uoDrz+zP84u3c9VTi3UgkrSZCl3EY5ERxm3n5vPo5SNZVlLJBU8sYr3mq0sbqNBFgsRFo3vxp+tOob6hmYue+Ij31uz2OpJ0MSp0kSAyOrcbr886lb6ZiXz3D4U8+eEmfVkqAVOhiwSZnNR4Xv7eRM4fnsODbxfzw5dWUN/Q5HUs6QJavGKRiHS++JhIHp8+mvzsZH757nq27Klj9tVjyUqJ8zqaBDHtoYsEKTPjB1MG8LurxrBuVw3THv+IotIqr2NJEFOhiwS5c4flMO/6CURGGJf9zz94Y+VOryNJkFKhi3QBQ3umsmDWqQzrmcqs55fxyDvraNYZG+WfqNBFuojuSbE8992vcNnYXjz2/kZufHGZTsMrx9CXoiJdSGxUJA9dOoK87on89/9bR3ZKHHdNHeJ1LAkSAe2hm9ktZrbazFaZ2QtmFmdmfc1ssZltMLM/mVlMR4cVEd+XpTdMOplrJuYxZ9EW/vDxVq8jSZBosdDN7CTgRqDAOTcMiASuAB4EHnXODQD2A9d2ZFAROdZdU4cwJT+Lu19fzQfF5V7HkSAQ6Bh6FBBvZlFAAlAGTAbm+R+fC1zY/vFE5ItERhiPTR/N4JwUZj2/lDU7q72OJB5rsdCdczuAh4Ht+Iq8ClgCVDrnGv2rlQInHe/5ZnadmRWaWWFFRUX7pBYRABJjo5gzYxzJcdFcO/dTdlfXex1JPBTIkEs34AKgL9ATSATOO86qx/263Tk32zlX4JwryMzMPJGsInIcPVLjmHNNAVUHG/j2s59Sd6ix5SdJSApkyOUsYItzrsI51wDMByYCaf4hGIBegI52EPHI0J6pPP5vo1lbVs1Nms4YtgIp9O3AKWaWYGYGTAHWAB8Al/rXmQEs6JiIIhKIyfnZ3DNtKO+tLee+N9d4HUc80OI8dOfcYjObBywFGoFlwGzgTeBFM7vPv2xORwYVkZZ9a0IeW/bU8cxHW8nLSGTGxDyvI0knCujAIufc3cDd/7R4MzC+3ROJyAm58+tDKNl3gHv/vJre6fFMzs/2OpJ0Eh36LxJiIiOMX18xmiE9U5j1/DJW79QZGsOFCl0kBH02nTE1Ppprny1kV5WmM4YDFbpIiMpOiePpa8ZRU6/pjOFChS4SwgbnpPD4lWMo3lXNjS9oOmOoU6GLhLhJg7K494JhLCwu52dvaDpjKNPpc0XCwNWn9GHbnjqeWrSFPhkJzDy1r9eRpAOo0EXCxB3nD2bbvgP87I015KYnMGWwpjOGGg25iIQJ33TGUQztmcoPXljGqh2azhhqVOgiYSQhJoo5MwpIi/ednbGs6qDXkaQdqdBFwkxWShxPzxxH3aEmvv1sIbWazhgyVOgiYSi/RwpPXDmG9btruPnFZTin6YyhQIUuEqbOGJjJnV8fzHtry5mzaIvXcaQdqNBFwtg1E/M4Z2g2D/ylmGXb93sdR06QCl0kjJkZD10ykh6pccx6fhlVBxq8jiQnQIUuEuZSE6L5zfTR7K6u58evrNB4ehemQhcRRud247Zz8/l/q3cz9x9bvY4jbaRCFxEAvnNaX6bkZ3H/W8UUleqgo65IhS4igG88/eHLRpKRFMOsF5ZSU6/x9K5GhS4iR3RLjOE300dTuv8gt88v0nh6F6NCF5FjFOSl86OzB/LmyjKe/2S713GkFVToIvIv/v30/pw+MJN7/7yGNTurvY4jAWqx0M1skJktP+qn2sxuNrN7zGzHUcvP74zAItLxIiKMR745krT4aGY9v1SXr+siWix059w659wo59woYCxwAHjV//Cjnz3mnHurI4OKSOfqnhTLY9NHs3VvHXe+tkrj6V1Aa4dcpgCbnHPbOiKMiASXU/plcNOUgby6bAcvF5Z6HUda0NpCvwJ44aj7s8xspZk9bWbd2jGXiASJWZNPZmL/DH76+irW767xOo58iYAL3cxigGnAy/5FTwL9gVFAGfDLL3jedWZWaGaFFRUVJxhXRDpbZITxqytGkRQbxQ3PLeXAYY2nB6vW7KGfByx1zu0GcM7tds41Oeeagf8Fxh/vSc652c65AudcQWZm5oknFpFOl5Ucx68uH83GilruXrDa6zjyBVpT6NM5arjFzHKOeuwiYFV7hRKR4PPVAd2ZNelkXl5SyvylGk8PRgEVupklAF8D5h+1+CEzKzKzlcAk4JYOyCciQeSmKQMYn5fOna+tYmN5rddx5J8EVOjOuQPOuQznXNVRy652zg13zo1wzk1zzpV1XEwRCQZRkRE8Nn00sVERzHp+KfUNTV5HkqPoSFERaZUeqXE8cvkoinfV8F9vrPE6jhxFhS4irTZpUBbfO6Mfzy/ezp9X7PQ6jvip0EWkTW49exBjctO4Y34RW/fUeR1HUKGLSBtFR0bwm38bQ2SEMeuFpRxq1Hi611ToItJmJ6XF8/BlI1m1o5oH/7LO6zhhT4UuIifka0OyufqUPjzzjy0s2bbf6zhhTYUuIifstvPyyUmJ47ZXVmroxUMqdBE5YUmxUfz84uFsLK/liQ82eR0nbKnQRaRdTBqUxYWjevLkhxsp3qWrHHlBhS4i7ean3xhKclw0t71SRFOzLojR2VToItJu0hNjuPsbQ1hRUskzH23xOk7YUaGLSLuaNrInk/Oz+OU76ynZd8DrOGFFhS4i7crMuO/CYURGGHfML9K1SDuRCl1E2l3PtHhuOy+fRRv38PISnTu9s6jQRaRDXDk+l/F56dz3xhrKa+q9jhMWVOgi0iEiIoxfXDKc+sZm7nldl63rDCp0Eekw/TOTuGnKAN4q2sXbq3Z5HSfkqdBFpENdd3o/Buek8NMFq6g62OB1nJCmQheRDhUdGcFDl4xgT+0hfvHWWq/jhDQVuoh0uOG9Uvnuaf148dMS/rFpj9dxQpYKXUQ6xc1nDSQvI4E75hdx8LDOyNgRVOgi0iniYyL5xcUj2Lb3AI++t97rOCGpxUI3s0Fmtvyon2ozu9nM0s3sXTPb4L/t1hmBRaTrmtA/g+nje/PU3zezsrTS6zghp8VCd86tc86Ncs6NAsYCB4BXgduBhc65AcBC/30RkS91+3mD6Z4Uy4/nraShqdnrOCGltUMuU4BNzrltwAXAXP/yucCF7RlMREJTanw09104jOJdNcz+22av44SU1hb6FcAL/t+znXNlAP7brPYMJiKh6+yhPfj68Bx+/d4GNpbXeh0nZARc6GYWA0wDXm7NC5jZdWZWaGaFFRUVrc0nIiHqnmlDiY+J5I75K2nWxTDaRWv20M8Dljrndvvv7zazHAD/bfnxnuScm+2cK3DOFWRmZp5YWhEJGZnJsdw1dQifbt3Pc4u3eR0nJLSm0Kfz+XALwOvADP/vM4AF7RVKRMLDJWNO4rQB3XngL8XsqDzodZwuL6BCN7ME4GvA/KMWPwB8zcw2+B97oP3jiUgoMzPuv2g4zQ7ufFUXwzhRARW6c+6Acy7DOVd11LK9zrkpzrkB/tt9HRdTREJV7/QEbj1nEB+sq+D1FTu9jtOl6UhREfHcNRPzGNU7jXv/vIa9tYe8jtNlqdBFxHOREcZDl46gpr6Be/+8xus4XZYKXUSCwsDsZGZNGsDrK3by7prdLT9B/oUKXUSCxvVn9ie/RzL/+WqRLobRBip0EQkaMVER/PelI9lbd5ifv6mhl9ZSoYtIUBneK5XrTu/HS4Wl/G29ji5vDRW6iASdm6YMoF9mInfML6L2UKPXcboMFbqIBJ246Ej++9IR7Kw6yENvF3sdp8tQoYtIUBrbJ52ZE/vy+4+3sXjzXq/jdAkqdBEJWreeM5Dc9ARue2WlrkMaABW6iASthJgoHrhkOFv3HuCRd9d5HSfoqdBFJKhN7N+df/tKLnMWbWHp9v1exwlqKnQRCXp3nJdPdkocP563kkONGnr5Iip0EQl6yXHR3H/xcDaW1/KbhRu9jhO0VOgi0iVMGpTFJWN68eRfN7FqR1XLTwhDKnQR6TLumjqY9MQYfjxvJQ1NzV7HCToqdBHpMtISYrjvwmGsKavmf/66yes4QUeFLiJdyjlDezB1RA6PLdzI+t01XscJKip0Eely7p02lKS4KP5j3kqamnUd0s+o0EWky8lIiuXubwxhRUklTy/a4nWcoKFCF5EuadrInpw1OJuH31nHlj11XscJCip0EemSzIyfXzSMmKgIbpu3kmYNvQRW6GaWZmbzzKzYzNaa2QQzu8fMdpjZcv/P+R0dVkTkaNkpcdw1dQifbN3HHxdv8zqO5wLdQ/818LZzLh8YCaz1L3/UOTfK//NWhyQUEfkSl43txWkDuvPAX4op2XfA6ziearHQzSwFOB2YA+CcO+ycq+zoYCIigTAzfnHxcAy4Y34RzoXv0Esge+j9gArgGTNbZmZPmVmi/7FZZrbSzJ42s27He7KZXWdmhWZWWFGh6wOKSPvr1S2B288fzKKNe3i5sNTrOJ4JpNCjgDHAk8650UAdcDvwJNAfGAWUAb883pOdc7OdcwXOuYLMzMz2SS0i8k+uHJ/L+L7p/OzNNeyqqvc6jicCKfRSoNQ5t9h/fx4wxjm32znX5JxrBv4XGN9RIUVEWhIRYTx0yQgampr5z1fDc+ilxUJ3zu0CSsxskH/RFGCNmeUctdpFwKoOyCciErC87oncevYgFhaX88rSHV7H6XRRAa73A+A5M4sBNgMzgcfMbBTggK3A9zokoYhIK8w8tS/vrNnNna8VMbRnCoNzUryO1GmsM/9bUlBQ4AoLCzvt9UQkPJXX1DP1sUXEx0Ty+qyvkhof7XWkE2JmS5xzBS2tpyNFRSTkZCXH8eRVY9ix/yA//NPysDmKVIUuIiFpbJ907po6hIXF5TzxQXhctk6FLiIh61sT+nDhqJ488t56/ro+9I+DUaGLSMgyM+6/eDiDspO56cVlIX9qABW6iIS0hJgofnfVWJqaHdc/t4T6hiavI3UYFbqIhLy87ok8+s1RrNpRzV2vrQrZg45U6CISFs4aks0PJp/My0tKefHTEq/jdAgVuoiEjZvPGsjpAzO5e8FqlpeE3kljVegiEjYiI4xfXz6KzORYvv/HJeytPeR1pHalQheRsNItMYbfXTWWPXWHufHFZTSF0EFHKnQRCTvDe6Vy3wXD+GjjXh5+Z53XcdqNCl1EwtI3x/Vm+vhcnvxwE2+v2uV1nHahQheRsHXPtCGM7JXKrS+vYHNFrddxTpgKXUTCVmxUJL+9aiwxURH8+x+XUHeo0etIJ0SFLiJh7aS0eH4zfTQby2u57ZWVXfqgIxW6iIS9U0/uzq3nDOKNlWU8/dFWr+O0mQpdRAS4/oz+nD0km/vfWssnW/Z5HadNVOgiIvjOzPjwN0fSJz2BG55fSnl1vdeRWk2FLiLilxIXze+uHkttfSPff24phxubvY7UKip0EZGjDMxO5sFLR1C4bT/3v7XW6zitEuV1ABGRYDNtZE+Wb6/k6Y+2MKRnCt8s6O11pIAEtIduZmlmNs/Mis1srZlNMLN0M3vXzDb4b7t1dFgRkc5yx/n5fPXk7twxv4gP15V7HScggQ65/Bp42zmXD4wE1gK3AwudcwOAhf77IiIhIToygievGsOg7GS+/9xSikqrvI7UohYL3cxSgNOBOQDOucPOuUrgAmCuf7W5wIUdFVJExAvJcdE8O3Mc3RJimPnsJ2zfG9zXJA1kD70fUAE8Y2bLzOwpM0sEsp1zZQD+26wOzCki4omslDjmfns8jc2OGc98wr66w15H+kKBFHoUMAZ40jk3GqijFcMrZnadmRWaWWFFRUUbY4qIeOfkrCSe+lYBOysP8u1nP+Xg4eC80HQghV4KlDrnFvvvz8NX8LvNLAfAf3vcbw2cc7OdcwXOuYLMzMz2yCwi0ukK8tJ5bPpoVpZW8oMXltLYFHxz1FssdOfcLqDEzAb5F00B1gCvAzP8y2YACzokoYhIkDhnaA/unTaU99aWc9eCVUF3Iq9A56H/AHjOzGKAzcBMfB8GL5nZtcB24LKOiSgiEjyunpBHWVU9v/1wEzmp8dw4ZYDXkY4IqNCdc8uBguM8NKV944iIBL//OGcQu6rreeTd9fRIjQuaA490pKiISCuZGQ9eMoKKmkPcMb+IzORYJg3yfqKfzuUiItIGvgOPxpLfI5nv/3EpK0oqvY6kQhcRaauk2CiemTmOjKQYvv3sp2zbW+dpHhW6iMgJyEr2HXjU5Bwznv6EvbWHPMuiQhcROUH9M5OYM2McZVX1fHtuIQcOe3OxaRW6iEg7GNunG7+ZPpqi0kpmPb/MkwOPVOgiIu3k7KE9+K8LhvF+cTl3vtb5Bx5p2qKISDu66pQ+7Kqq5/EPNtIjNY6bzxrYaa+tQhcRaWc/OnsgZVX1/Oq9DeSkxnH5uNxOeV0VuohIOzMzHrhkOBW1h/jJq6vITI5lcn52h7+uxtBFRDpAdGQEv71yDINzkrnhuWUs74QDj1ToIiIdJCk2iqevGUdBXjfS4qM7/PU05CIi0oGykuP4w7Vf6ZTX0h66iEiIUKGLiIQIFbqISIhQoYuIhAgVuohIiFChi4iECBW6iEiIUKGLiIQI68zTO5pZBbCt016wY3UH9ngdIojp/fliem++nN6ff9XHOZfZ0kqdWuihxMwKnXMFXucIVnp/vpjemy+n96ftNOQiIhIiVOgiIiFChd52s70OEOT0/nwxvTdfTu9PG2kMXUQkRGgPXUQkRKjQW2Bmvc3sAzNba2arzewm//J0M3vXzDb4b7t5ndVLZhZpZsvM7A3//b5mttj//vzJzGK8zugVM0szs3lmVuzfjiZo+/Exs1v8/65WmdkLZhanbaftVOgtawR+5JwbDJwC3GBmQ4DbgYXOuQHAQv/9cHYTsPao+w8Cj/rfn/3AtZ6kCg6/Bt52zuUDI/G9T2G//ZjZScCNQIFzbhgQCVyBtp02U6G3wDlX5pxb6v+9Bt8/xpOAC4C5/tXmAhd6k9B7ZtYL+DrwlP++AZOBef5Vwvb9MbMU4HRgDoBz7rBzrhJtP5+JAuLNLApIAMrQttNmKvRWMLM8YDSwGMh2zpWBr/SBLO+See5XwI+BZv/9DKDSOdfov1+K70MwHPUDKoBn/ENST5lZItp+cM7tAB4GtuMr8ipgCdp22kyFHiAzSwJeAW52zlV7nSdYmNlUoNw5t+ToxcdZNVynU0UBY4AnnXOjgTrCcHjlePzfG1xf/hHGAAABSklEQVQA9AV6AonAecdZNVy3nVZToQfAzKLxlflzzrn5/sW7zSzH/3gOUO5VPo+dCkwzs63Ai/j+u/wrIM3/32iAXsBOb+J5rhQodc4t9t+fh6/gtf3AWcAW51yFc64BmA9MRNtOm6nQW+AfD54DrHXOPXLUQ68DM/y/zwAWdHa2YOCcu8M518s5l4fvC633nXNXAh8Al/pXC+f3ZxdQYmaD/IumAGvQ9gO+oZZTzCzB/+/ss/dG204b6cCiFpjZV4G/A0V8Pkb8E3zj6C8Bufg2zMucc/s8CRkkzOxM4Fbn3FQz64dvjz0dWAZc5Zw75GU+r5jZKHxfGMcAm4GZ+Hamwn77MbN7gcvxzSZbBnwH35i5tp02UKGLiIQIDbmIiIQIFbqISIhQoYuIhAgVuohIiFChi4iECBW6iEiIUKGLiIQIFbqISIj4/9rooDDcUHdQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ans = [89.61,89.42,89.25,89.07,88.61,88.14,87.69,87.07,86.21,84.91,83.10,80.69,77.29,73.37,68.85,64.40,60.67,57.39]\n",
    "xaxis = [10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95]\n",
    "plt.plot(xaxis,ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
